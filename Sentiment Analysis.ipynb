{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li>The inbound feature is important because it allows you to distinguish between company and customer.</li>\n",
    "<li>Obviously the 'text' function is the main source of information.</li>\n",
    "<li>I will apply natural language processing techniques. In my opinion, it is possible to address the problem in two ways:</li>\n",
    "    <ul><li>Catalog customer tweets and identify the most discussed topics;</li>\n",
    "        <li>Create a model that adapts to the tweets of the companies and try to answer a specific topic of a customer (to do)</li></ul>\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Geting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twcs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1037970</th>\n",
       "      <td>1149252</td>\n",
       "      <td>390440</td>\n",
       "      <td>True</td>\n",
       "      <td>Sun Oct 15 17:06:48 +0000 2017</td>\n",
       "      <td>@AskPlayStation how come my audio with the Pla...</td>\n",
       "      <td>1149251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027912</th>\n",
       "      <td>1137919</td>\n",
       "      <td>388026</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 24 02:07:46 +0000 2017</td>\n",
       "      <td>Damn @115937 is from San Jose and my brother  ...</td>\n",
       "      <td>1137918</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905093</th>\n",
       "      <td>767149</td>\n",
       "      <td>ChaseSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Sat Oct 07 14:57:29 +0000 2017</td>\n",
       "      <td>@303346 1/2 We're sorry to hear about your rec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970880</th>\n",
       "      <td>1077275</td>\n",
       "      <td>374155</td>\n",
       "      <td>True</td>\n",
       "      <td>Fri Oct 13 14:19:58 +0000 2017</td>\n",
       "      <td>@AppleSupport Thanks a million. It is just res...</td>\n",
       "      <td>1077272</td>\n",
       "      <td>1077276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419301</th>\n",
       "      <td>1561934</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>Sat Nov 04 09:57:28 +0000 2017</td>\n",
       "      <td>@482486 This feature is not available yet. I'l...</td>\n",
       "      <td>1561935</td>\n",
       "      <td>1561936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217598</th>\n",
       "      <td>1343129</td>\n",
       "      <td>267514</td>\n",
       "      <td>True</td>\n",
       "      <td>Mon Oct 16 08:01:10 +0000 2017</td>\n",
       "      <td>@115873 @Uber_Support @4018 Their numbers didn...</td>\n",
       "      <td>1343128</td>\n",
       "      <td>1343130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512284</th>\n",
       "      <td>1659600</td>\n",
       "      <td>Uber_Support</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 17 14:49:10 +0000 2017</td>\n",
       "      <td>@160540 Here to help! Send us a note here; htt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1659601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817103</th>\n",
       "      <td>910578</td>\n",
       "      <td>336276</td>\n",
       "      <td>True</td>\n",
       "      <td>Fri Oct 13 18:44:03 +0000 2017</td>\n",
       "      <td>@115858 That doesn’t close me out of apps and ...</td>\n",
       "      <td>910577</td>\n",
       "      <td>910579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905203</th>\n",
       "      <td>1005402</td>\n",
       "      <td>335124</td>\n",
       "      <td>True</td>\n",
       "      <td>Sun Oct 22 19:21:38 +0000 2017</td>\n",
       "      <td>@GWRHelp I've already rung your helpline. This...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252198</th>\n",
       "      <td>290519</td>\n",
       "      <td>AppleSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Mon Oct 09 15:58:31 +0000 2017</td>\n",
       "      <td>@185186 Let's look into this particular issue ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290518.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id     author_id  inbound                      created_at  \\\n",
       "1037970   1149252        390440     True  Sun Oct 15 17:06:48 +0000 2017   \n",
       "1027912   1137919        388026     True  Tue Oct 24 02:07:46 +0000 2017   \n",
       "1905093    767149  ChaseSupport    False  Sat Oct 07 14:57:29 +0000 2017   \n",
       "970880    1077275        374155     True  Fri Oct 13 14:19:58 +0000 2017   \n",
       "1419301   1561934    AmazonHelp    False  Sat Nov 04 09:57:28 +0000 2017   \n",
       "1217598   1343129        267514     True  Mon Oct 16 08:01:10 +0000 2017   \n",
       "1512284   1659600  Uber_Support    False  Tue Oct 17 14:49:10 +0000 2017   \n",
       "817103     910578        336276     True  Fri Oct 13 18:44:03 +0000 2017   \n",
       "905203    1005402        335124     True  Sun Oct 22 19:21:38 +0000 2017   \n",
       "252198     290519  AppleSupport    False  Mon Oct 09 15:58:31 +0000 2017   \n",
       "\n",
       "                                                      text response_tweet_id  \\\n",
       "1037970  @AskPlayStation how come my audio with the Pla...           1149251   \n",
       "1027912  Damn @115937 is from San Jose and my brother  ...           1137918   \n",
       "1905093  @303346 1/2 We're sorry to hear about your rec...               NaN   \n",
       "970880   @AppleSupport Thanks a million. It is just res...           1077272   \n",
       "1419301  @482486 This feature is not available yet. I'l...           1561935   \n",
       "1217598  @115873 @Uber_Support @4018 Their numbers didn...           1343128   \n",
       "1512284  @160540 Here to help! Send us a note here; htt...               NaN   \n",
       "817103   @115858 That doesn’t close me out of apps and ...            910577   \n",
       "905203   @GWRHelp I've already rung your helpline. This...               NaN   \n",
       "252198   @185186 Let's look into this particular issue ...               NaN   \n",
       "\n",
       "         in_response_to_tweet_id  \n",
       "1037970                      NaN  \n",
       "1027912                      NaN  \n",
       "1905093                 767148.0  \n",
       "970880                 1077276.0  \n",
       "1419301                1561936.0  \n",
       "1217598                1343130.0  \n",
       "1512284                1659601.0  \n",
       "817103                  910579.0  \n",
       "905203                 1005401.0  \n",
       "252198                  290518.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2811774, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2811774 entries, 0 to 2811773\n",
      "Data columns (total 7 columns):\n",
      "tweet_id                   int64\n",
      "author_id                  object\n",
      "inbound                    bool\n",
      "created_at                 object\n",
      "text                       object\n",
      "response_tweet_id          object\n",
      "in_response_to_tweet_id    float64\n",
      "dtypes: bool(1), float64(1), int64(1), object(4)\n",
      "memory usage: 131.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Checking missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                         0\n",
       "author_id                        0\n",
       "inbound                          0\n",
       "created_at                       0\n",
       "text                             0\n",
       "response_tweet_id          1040629\n",
       "in_response_to_tweet_id     794335\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first inbound = Richiesta iniziale di un cliente\n",
    "first_inbound = df[pd.isnull(df.in_response_to_tweet_id) & df.inbound]\n",
    "\n",
    "inbOutb = pd.merge(first_inbound, df, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id').sample(frac=1)\n",
    "\n",
    "# Filter to only outbound replies (from companies)\n",
    "inbOutb = inbOutb[inbOutb.inbound_y ^ True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794299, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now the dataset is doubled in size (features), as each line contains:</b>\n",
    "<ul><li>a customer request (text_x)</li>\n",
    "    <li>a reply from the company (text_y)</li>\n",
    "    <li>Related related features</li></ul>\n",
    "\n",
    "<b>From which we can easily verify that:</b>\n",
    "<ul><li>the 'inbound_x' feature is always True;</li>\n",
    "    <li>the 'inbound_y' feature is always False;</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id_x                        0\n",
       "author_id_x                       0\n",
       "inbound_x                         0\n",
       "created_at_x                      0\n",
       "text_x                            0\n",
       "response_tweet_id_x               0\n",
       "in_response_to_tweet_id_x    794299\n",
       "tweet_id_y                        0\n",
       "author_id_y                       0\n",
       "inbound_y                         0\n",
       "created_at_y                      0\n",
       "text_y                            0\n",
       "response_tweet_id_y          530528\n",
       "in_response_to_tweet_id_y         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>'in_response_to_tweet_id_x'</b> feature is totally composed of <b>NaN.</b> So this feature will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Drop useless features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id_x', 'author_id_x', 'inbound_x', 'created_at_x', 'text_x',\n",
       "       'response_tweet_id_x', 'in_response_to_tweet_id_x', 'tweet_id_y',\n",
       "       'author_id_y', 'inbound_y', 'created_at_y', 'text_y',\n",
       "       'response_tweet_id_y', 'in_response_to_tweet_id_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "toDrop = ['tweet_id_x', 'inbound_x','response_tweet_id_x', 'in_response_to_tweet_id_x', \n",
    "          'tweet_id_y', 'inbound_y','response_tweet_id_y', 'in_response_to_tweet_id_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inbOutb shape:  (794299, 6)\n"
     ]
    }
   ],
   "source": [
    "inbOutb.drop(toDrop, axis=1, inplace=True)\n",
    "print('inbOutb shape: ', inbOutb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277971</th>\n",
       "      <td>361414</td>\n",
       "      <td>Fri Oct 13 03:12:48 +0000 2017</td>\n",
       "      <td>@hulu_support I'm getting this message when I ...</td>\n",
       "      <td>hulu_support</td>\n",
       "      <td>Sat Oct 14 16:03:24 +0000 2017</td>\n",
       "      <td>@361414 Sorry for the delay! Try power cycling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635209</th>\n",
       "      <td>644104</td>\n",
       "      <td>Thu Nov 09 21:17:05 +0000 2017</td>\n",
       "      <td>@AmericanAir gate k16 at OHare today was a dam...</td>\n",
       "      <td>AmericanAir</td>\n",
       "      <td>Thu Nov 09 21:43:02 +0000 2017</td>\n",
       "      <td>@644104 We don't want you feeling this way, ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732023</th>\n",
       "      <td>717611</td>\n",
       "      <td>Thu Nov 16 00:11:03 +0000 2017</td>\n",
       "      <td>hey @117735 @AppleSupport ... both myself and ...</td>\n",
       "      <td>AppleSupport</td>\n",
       "      <td>Thu Nov 16 01:12:31 +0000 2017</td>\n",
       "      <td>@717611 Thank you for reaching out. Please nav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202570</th>\n",
       "      <td>299257</td>\n",
       "      <td>Mon Oct 23 19:28:06 +0000 2017</td>\n",
       "      <td>That's over three hours in two days spent on t...</td>\n",
       "      <td>VirginAtlantic</td>\n",
       "      <td>Mon Oct 23 21:15:02 +0000 2017</td>\n",
       "      <td>@299257 @299258 Sorry to hear you're not happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830041</th>\n",
       "      <td>790310</td>\n",
       "      <td>Mon Nov 27 16:02:00 +0000 2017</td>\n",
       "      <td>@115911 @TMobileHelp Beste T Mobile ik heb sin...</td>\n",
       "      <td>TMobileHelp</td>\n",
       "      <td>Mon Nov 27 16:05:49 +0000 2017</td>\n",
       "      <td>@790310 Hey there, welcome to T-Force! We woul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "277971      361414  Fri Oct 13 03:12:48 +0000 2017   \n",
       "635209      644104  Thu Nov 09 21:17:05 +0000 2017   \n",
       "732023      717611  Thu Nov 16 00:11:03 +0000 2017   \n",
       "202570      299257  Mon Oct 23 19:28:06 +0000 2017   \n",
       "830041      790310  Mon Nov 27 16:02:00 +0000 2017   \n",
       "\n",
       "                                                   text_x     author_id_y  \\\n",
       "277971  @hulu_support I'm getting this message when I ...    hulu_support   \n",
       "635209  @AmericanAir gate k16 at OHare today was a dam...     AmericanAir   \n",
       "732023  hey @117735 @AppleSupport ... both myself and ...    AppleSupport   \n",
       "202570  That's over three hours in two days spent on t...  VirginAtlantic   \n",
       "830041  @115911 @TMobileHelp Beste T Mobile ik heb sin...     TMobileHelp   \n",
       "\n",
       "                          created_at_y  \\\n",
       "277971  Sat Oct 14 16:03:24 +0000 2017   \n",
       "635209  Thu Nov 09 21:43:02 +0000 2017   \n",
       "732023  Thu Nov 16 01:12:31 +0000 2017   \n",
       "202570  Mon Oct 23 21:15:02 +0000 2017   \n",
       "830041  Mon Nov 27 16:05:49 +0000 2017   \n",
       "\n",
       "                                                   text_y  \n",
       "277971  @361414 Sorry for the delay! Try power cycling...  \n",
       "635209  @644104 We don't want you feeling this way, ou...  \n",
       "732023  @717611 Thank you for reaching out. Please nav...  \n",
       "202570  @299257 @299258 Sorry to hear you're not happy...  \n",
       "830041  @790310 Hey there, welcome to T-Force! We woul...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 794299 entries, 538902 to 769548\n",
      "Data columns (total 6 columns):\n",
      "author_id_x     794299 non-null object\n",
      "created_at_x    794299 non-null object\n",
      "text_x          794299 non-null object\n",
      "author_id_y     794299 non-null object\n",
      "created_at_y    794299 non-null object\n",
      "text_y          794299 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 42.4+ MB\n"
     ]
    }
   ],
   "source": [
    "inbOutb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794299, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Lower Casing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower casing is a common text preprocessing technique. The idea is to convert the input text into same casing format so that 'text', 'Text' and 'TEXT' are treated the same way.\n",
    "\n",
    "This is more helpful for text featurization techniques like frequency, tfidf as it helps to combine the same words together thereby reducing the duplication and get correct counts / tfidf values.\n",
    "\n",
    "This may not be helpful when we do tasks like Part of Speech tagging (where proper casing gives some information about Nouns and so on) and Sentiment Analysis (where upper casing refers to anger and so on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_uppercase(text):\n",
    "    text_lowercase = ' '.join(x.lower() for x in text.split())# It will discard all uppercases\n",
    "    return text_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbOutb['text_x_clean'] = inbOutb['text_x'].apply(lambda x: remove_uppercase(x))\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y'].apply(lambda x: remove_uppercase(x))\n",
    "#in modo da poter rimuovere i nomi delle compagnie\n",
    "inbOutb['author_id_y'] = inbOutb['author_id_y'].apply(lambda x: remove_uppercase(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538902</th>\n",
       "      <td>568875</td>\n",
       "      <td>Wed Oct 18 09:54:26 +0000 2017</td>\n",
       "      <td>Hey @GloCare your LTE data service is becoming...</td>\n",
       "      <td>glocare</td>\n",
       "      <td>Wed Oct 18 13:08:38 +0000 2017</td>\n",
       "      <td>@568875 Afternoon Tari, may we know the exact ...</td>\n",
       "      <td>hey @glocare your lte data service is becoming...</td>\n",
       "      <td>@568875 afternoon tari, may we know the exact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127066</th>\n",
       "      <td>230636</td>\n",
       "      <td>Fri Dec 01 14:34:28 +0000 2017</td>\n",
       "      <td>If I can’t access tracking, how will I know wh...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 15:05:00 +0000 2017</td>\n",
       "      <td>@230636 Apologies for the concern, Stephanie! ...</td>\n",
       "      <td>if i can’t access tracking, how will i know wh...</td>\n",
       "      <td>@230636 apologies for the concern, stephanie! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132865</th>\n",
       "      <td>236039</td>\n",
       "      <td>Fri Dec 01 20:57:53 +0000 2017</td>\n",
       "      <td>soooo glad i pay for amazon prime for my packa...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 20:59:40 +0000 2017</td>\n",
       "      <td>@236039 Did we miss the delivery date in the c...</td>\n",
       "      <td>soooo glad i pay for amazon prime for my packa...</td>\n",
       "      <td>@236039 did we miss the delivery date in the c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "538902      568875  Wed Oct 18 09:54:26 +0000 2017   \n",
       "127066      230636  Fri Dec 01 14:34:28 +0000 2017   \n",
       "132865      236039  Fri Dec 01 20:57:53 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "538902  Hey @GloCare your LTE data service is becoming...     glocare   \n",
       "127066  If I can’t access tracking, how will I know wh...  amazonhelp   \n",
       "132865  soooo glad i pay for amazon prime for my packa...  amazonhelp   \n",
       "\n",
       "                          created_at_y  \\\n",
       "538902  Wed Oct 18 13:08:38 +0000 2017   \n",
       "127066  Fri Dec 01 15:05:00 +0000 2017   \n",
       "132865  Fri Dec 01 20:59:40 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "538902  @568875 Afternoon Tari, may we know the exact ...   \n",
       "127066  @230636 Apologies for the concern, Stephanie! ...   \n",
       "132865  @236039 Did we miss the delivery date in the c...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "538902  hey @glocare your lte data service is becoming...   \n",
       "127066  if i can’t access tracking, how will i know wh...   \n",
       "132865  soooo glad i pay for amazon prime for my packa...   \n",
       "\n",
       "                                             text_y_clean  \n",
       "538902  @568875 afternoon tari, may we know the exact ...  \n",
       "127066  @230636 apologies for the concern, stephanie! ...  \n",
       "132865  @236039 did we miss the delivery date in the c...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Remove Puntuaction\n",
    "\n",
    "Punctuation can provide grammatical context to a sentence which supports our understanding. But for our vectorizer which counts the number of words and not the context, it does not add value, so we remove all special characters. eg: How are you?->How are you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538902</th>\n",
       "      <td>568875</td>\n",
       "      <td>Wed Oct 18 09:54:26 +0000 2017</td>\n",
       "      <td>Hey @GloCare your LTE data service is becoming...</td>\n",
       "      <td>glocare</td>\n",
       "      <td>Wed Oct 18 13:08:38 +0000 2017</td>\n",
       "      <td>@568875 Afternoon Tari, may we know the exact ...</td>\n",
       "      <td>hey glocare your lte data service is becoming ...</td>\n",
       "      <td>568875 afternoon tari may we know the exact is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127066</th>\n",
       "      <td>230636</td>\n",
       "      <td>Fri Dec 01 14:34:28 +0000 2017</td>\n",
       "      <td>If I can’t access tracking, how will I know wh...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 15:05:00 +0000 2017</td>\n",
       "      <td>@230636 Apologies for the concern, Stephanie! ...</td>\n",
       "      <td>if i can’t access tracking how will i know whe...</td>\n",
       "      <td>230636 apologies for the concern stephanie cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132865</th>\n",
       "      <td>236039</td>\n",
       "      <td>Fri Dec 01 20:57:53 +0000 2017</td>\n",
       "      <td>soooo glad i pay for amazon prime for my packa...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 20:59:40 +0000 2017</td>\n",
       "      <td>@236039 Did we miss the delivery date in the c...</td>\n",
       "      <td>soooo glad i pay for amazon prime for my packa...</td>\n",
       "      <td>236039 did we miss the delivery date in the co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "538902      568875  Wed Oct 18 09:54:26 +0000 2017   \n",
       "127066      230636  Fri Dec 01 14:34:28 +0000 2017   \n",
       "132865      236039  Fri Dec 01 20:57:53 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "538902  Hey @GloCare your LTE data service is becoming...     glocare   \n",
       "127066  If I can’t access tracking, how will I know wh...  amazonhelp   \n",
       "132865  soooo glad i pay for amazon prime for my packa...  amazonhelp   \n",
       "\n",
       "                          created_at_y  \\\n",
       "538902  Wed Oct 18 13:08:38 +0000 2017   \n",
       "127066  Fri Dec 01 15:05:00 +0000 2017   \n",
       "132865  Fri Dec 01 20:59:40 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "538902  @568875 Afternoon Tari, may we know the exact ...   \n",
       "127066  @230636 Apologies for the concern, Stephanie! ...   \n",
       "132865  @236039 Did we miss the delivery date in the c...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "538902  hey glocare your lte data service is becoming ...   \n",
       "127066  if i can’t access tracking how will i know whe...   \n",
       "132865  soooo glad i pay for amazon prime for my packa...   \n",
       "\n",
       "                                             text_y_clean  \n",
       "538902  568875 afternoon tari may we know the exact is...  \n",
       "127066  230636 apologies for the concern stephanie cou...  \n",
       "132865  236039 did we miss the delivery date in the co...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to remove Punctuation\n",
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])# It will discard all punctuations\n",
    "    return text_nopunct\n",
    "inbOutb['text_x_clean'] = inbOutb['text_x_clean'].apply(lambda x: remove_punct(x))\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y_clean'].apply(lambda x: remove_punct(x))\n",
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Removing usernames\n",
    "rimuovere nomi utenti, compagnie da text_x_clean<br>\n",
    "rimuovere nomi utenti, compagnie da text_y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538902</th>\n",
       "      <td>568875</td>\n",
       "      <td>Wed Oct 18 09:54:26 +0000 2017</td>\n",
       "      <td>Hey @GloCare your LTE data service is becoming...</td>\n",
       "      <td>glocare</td>\n",
       "      <td>Wed Oct 18 13:08:38 +0000 2017</td>\n",
       "      <td>@568875 Afternoon Tari, may we know the exact ...</td>\n",
       "      <td>hey  your lte data service is becoming terribl...</td>\n",
       "      <td>afternoon tari may we know the exact issue be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127066</th>\n",
       "      <td>230636</td>\n",
       "      <td>Fri Dec 01 14:34:28 +0000 2017</td>\n",
       "      <td>If I can’t access tracking, how will I know wh...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 15:05:00 +0000 2017</td>\n",
       "      <td>@230636 Apologies for the concern, Stephanie! ...</td>\n",
       "      <td>if i can’t access tracking how will i know whe...</td>\n",
       "      <td>apologies for the concern stephanie could you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132865</th>\n",
       "      <td>236039</td>\n",
       "      <td>Fri Dec 01 20:57:53 +0000 2017</td>\n",
       "      <td>soooo glad i pay for amazon prime for my packa...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 20:59:40 +0000 2017</td>\n",
       "      <td>@236039 Did we miss the delivery date in the c...</td>\n",
       "      <td>soooo glad i pay for amazon prime for my packa...</td>\n",
       "      <td>did we miss the delivery date in the confirma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "538902      568875  Wed Oct 18 09:54:26 +0000 2017   \n",
       "127066      230636  Fri Dec 01 14:34:28 +0000 2017   \n",
       "132865      236039  Fri Dec 01 20:57:53 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "538902  Hey @GloCare your LTE data service is becoming...     glocare   \n",
       "127066  If I can’t access tracking, how will I know wh...  amazonhelp   \n",
       "132865  soooo glad i pay for amazon prime for my packa...  amazonhelp   \n",
       "\n",
       "                          created_at_y  \\\n",
       "538902  Wed Oct 18 13:08:38 +0000 2017   \n",
       "127066  Fri Dec 01 15:05:00 +0000 2017   \n",
       "132865  Fri Dec 01 20:59:40 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "538902  @568875 Afternoon Tari, may we know the exact ...   \n",
       "127066  @230636 Apologies for the concern, Stephanie! ...   \n",
       "132865  @236039 Did we miss the delivery date in the c...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "538902  hey  your lte data service is becoming terribl...   \n",
       "127066  if i can’t access tracking how will i know whe...   \n",
       "132865  soooo glad i pay for amazon prime for my packa...   \n",
       "\n",
       "                                             text_y_clean  \n",
       "538902   afternoon tari may we know the exact issue be...  \n",
       "127066   apologies for the concern stephanie could you...  \n",
       "132865   did we miss the delivery date in the confirma...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = inbOutb['author_id_y'].unique()\n",
    "\n",
    "inbOutb['text_x_clean'] = inbOutb['text_x_clean'].str.replace('\\d+', '')\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y_clean'].str.replace('\\d+', '')\n",
    "\n",
    "inbOutb['text_x_clean'] = inbOutb['text_x_clean'].str.replace('|'.join(companies), '')\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y_clean'].str.replace('|'.join(companies), '')\n",
    "\n",
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794299, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Removal of stopwords\n",
    "Stopwords are commonly occuring words in a language like 'the', 'a' and so on. They can be removed from the text most of the times, as they don't provide valuable information for downstream analysis. In cases like Part of Speech tagging, we should not remove them as provide very valuable information about the POS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Similarly we can also get the list for other languages as well and use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "      <th>text_wo_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538902</th>\n",
       "      <td>568875</td>\n",
       "      <td>Wed Oct 18 09:54:26 +0000 2017</td>\n",
       "      <td>Hey @GloCare your LTE data service is becoming...</td>\n",
       "      <td>glocare</td>\n",
       "      <td>Wed Oct 18 13:08:38 +0000 2017</td>\n",
       "      <td>@568875 Afternoon Tari, may we know the exact ...</td>\n",
       "      <td>hey  your lte data service is becoming terribl...</td>\n",
       "      <td>afternoon tari may we know the exact issue be...</td>\n",
       "      <td>afternoon tari may know exact issue experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127066</th>\n",
       "      <td>230636</td>\n",
       "      <td>Fri Dec 01 14:34:28 +0000 2017</td>\n",
       "      <td>If I can’t access tracking, how will I know wh...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 15:05:00 +0000 2017</td>\n",
       "      <td>@230636 Apologies for the concern, Stephanie! ...</td>\n",
       "      <td>if i can’t access tracking how will i know whe...</td>\n",
       "      <td>apologies for the concern stephanie could you...</td>\n",
       "      <td>apologies concern stephanie could please confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132865</th>\n",
       "      <td>236039</td>\n",
       "      <td>Fri Dec 01 20:57:53 +0000 2017</td>\n",
       "      <td>soooo glad i pay for amazon prime for my packa...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 20:59:40 +0000 2017</td>\n",
       "      <td>@236039 Did we miss the delivery date in the c...</td>\n",
       "      <td>soooo glad i pay for amazon prime for my packa...</td>\n",
       "      <td>did we miss the delivery date in the confirma...</td>\n",
       "      <td>miss delivery date confirmation email check ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "538902      568875  Wed Oct 18 09:54:26 +0000 2017   \n",
       "127066      230636  Fri Dec 01 14:34:28 +0000 2017   \n",
       "132865      236039  Fri Dec 01 20:57:53 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "538902  Hey @GloCare your LTE data service is becoming...     glocare   \n",
       "127066  If I can’t access tracking, how will I know wh...  amazonhelp   \n",
       "132865  soooo glad i pay for amazon prime for my packa...  amazonhelp   \n",
       "\n",
       "                          created_at_y  \\\n",
       "538902  Wed Oct 18 13:08:38 +0000 2017   \n",
       "127066  Fri Dec 01 15:05:00 +0000 2017   \n",
       "132865  Fri Dec 01 20:59:40 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "538902  @568875 Afternoon Tari, may we know the exact ...   \n",
       "127066  @230636 Apologies for the concern, Stephanie! ...   \n",
       "132865  @236039 Did we miss the delivery date in the c...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "538902  hey  your lte data service is becoming terribl...   \n",
       "127066  if i can’t access tracking how will i know whe...   \n",
       "132865  soooo glad i pay for amazon prime for my packa...   \n",
       "\n",
       "                                             text_y_clean  \\\n",
       "538902   afternoon tari may we know the exact issue be...   \n",
       "127066   apologies for the concern stephanie could you...   \n",
       "132865   did we miss the delivery date in the confirma...   \n",
       "\n",
       "                                             text_wo_stop  \n",
       "538902  afternoon tari may know exact issue experience...  \n",
       "127066  apologies concern stephanie could please confi...  \n",
       "132865  miss delivery date confirmation email check ht...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "inbOutb['text_wo_stop'] = inbOutb['text_x_clean'].apply(lambda x: remove_stopwords(x))\n",
    "inbOutb['text_wo_stop'] = inbOutb['text_y_clean'].apply(lambda y: remove_stopwords(y))\n",
    "\n",
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5  Checking Most Common Worlds\n",
    "Previously, we just removed commonly occurring words in a general sense. We can also remove commonly occurring words from our text data First, let’s check the 10 most frequently occurring words in our text data then take call to remove or retain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ X: \n",
      " to     450771\n",
      "i      402429\n",
      "the    394086\n",
      "my     310607\n",
      "a      289704\n",
      "and    250549\n",
      "is     210765\n",
      "for    199934\n",
      "on     184365\n",
      "you    172960\n",
      "dtype: int64 \n",
      "FREQ Y: \n",
      " to      597010\n",
      "you     562841\n",
      "the     438571\n",
      "your    355927\n",
      "we      300935\n",
      "us      281678\n",
      "for     280735\n",
      "can     262541\n",
      "a       257072\n",
      "this    245768\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#common worlds\n",
    "\n",
    "freqX = pd.Series(' '.join(inbOutb['text_x_clean']).split()).value_counts()[:10]\n",
    "freqY = pd.Series(' '.join(inbOutb['text_y_clean']).split()).value_counts()[:10]\n",
    "print('FREQ X: \\n',freqX,'\\nFREQ Y: \\n', freqY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing them\n",
    "freqX = list(freqX.index)\n",
    "freqY = list(freqY.index)\n",
    "inbOutb['text_x_clean'] = inbOutb['text_x_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in freqX))\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in freqY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Checking Most Rare Worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RARE X: \n",
      " httpstcoryaustq                                                                                                                                                                                                                 1\n",
      "orz                                                                                                                                                                                                                             1\n",
      "’order                                                                                                                                                                                                                          1\n",
      "возврата                                                                                                                                                                                                                        1\n",
      "httpstcowjgxwcckd                                                                                                                                                                                                               1\n",
      "httpstcokldrmik                                                                                                                                                                                                                 1\n",
      "httpstcorbfxvmyrw                                                                                                                                                                                                               1\n",
      "screwin’                                                                                                                                                                                                                        1\n",
      "snaresbrook                                                                                                                                                                                                                     1\n",
      "httpstcozhuaymxjz                                                                                                                                                                                                               1\n",
      "heymyspacebarwasstuckanditriedtogetitworkagianhoweverwhenitriedtogetitmoreloseitpoppedoutofmykeyboardandcantgetitbackincanyouguyshelpmeouihaveaprojecttomakeforschoolbuticantmakeanyprogressthiswaypleasehelpitssooooanoying    1\n",
      "forcenturylink                                                                                                                                                                                                                  1\n",
      "httpstcouhfmwxdsh                                                                                                                                                                                                               1\n",
      "cmgftw                                                                                                                                                                                                                          1\n",
      "“cake”                                                                                                                                                                                                                          1\n",
      "hinkriegt                                                                                                                                                                                                                       1\n",
      "httpstcotmbvdk                                                                                                                                                                                                                  1\n",
      "stratford😡                                                                                                                                                                                                                      1\n",
      "shouldbegiventhemoneyback                                                                                                                                                                                                       1\n",
      "httpstcoidormpotc                                                                                                                                                                                                               1\n",
      "greatbusinessmodel                                                                                                                                                                                                              1\n",
      "podáis                                                                                                                                                                                                                          1\n",
      "tmobilehow                                                                                                                                                                                                                      1\n",
      "zwangsportrait                                                                                                                                                                                                                  1\n",
      "restartsbeyond                                                                                                                                                                                                                  1\n",
      "adelphia                                                                                                                                                                                                                        1\n",
      "httpstcoikgcyxfzi                                                                                                                                                                                                               1\n",
      "noharmintrying                                                                                                                                                                                                                  1\n",
      "httpstcovknplbtfx                                                                                                                                                                                                               1\n",
      "httpstcovaqvujcc                                                                                                                                                                                                                1\n",
      "                                                                                                                                                                                                                               ..\n",
      "httpstcoimrgfedf                                                                                                                                                                                                                1\n",
      "httpstcomwbqrdg                                                                                                                                                                                                                 1\n",
      "httpstcoqsbjkofo                                                                                                                                                                                                                1\n",
      "justmythoughts                                                                                                                                                                                                                  1\n",
      "httpstcotwcsubbo                                                                                                                                                                                                                1\n",
      "recmnd                                                                                                                                                                                                                          1\n",
      "httpstcoerncktltal                                                                                                                                                                                                              1\n",
      "httpstcoatrokruij                                                                                                                                                                                                               1\n",
      "httpstcoecuiegkfvd                                                                                                                                                                                                              1\n",
      "bgtym                                                                                                                                                                                                                           1\n",
      "httpstcolrfqxggos                                                                                                                                                                                                               1\n",
      "heresomebody                                                                                                                                                                                                                    1\n",
      "correctwaiting                                                                                                                                                                                                                  1\n",
      "httpstcomnrpmnja                                                                                                                                                                                                                1\n",
      "httpstcozgindzprc                                                                                                                                                                                                               1\n",
      "cherai                                                                                                                                                                                                                          1\n",
      "jast                                                                                                                                                                                                                            1\n",
      "httpstcoemfcwxdn                                                                                                                                                                                                                1\n",
      "thoughit                                                                                                                                                                                                                        1\n",
      "httpstcootdamcge                                                                                                                                                                                                                1\n",
      "httpstcozvodgczipz                                                                                                                                                                                                              1\n",
      "mitlerweile                                                                                                                                                                                                                     1\n",
      "httpstcoyphtftyr                                                                                                                                                                                                                1\n",
      "httpstcocqdihlkjb                                                                                                                                                                                                               1\n",
      "portlandoregon                                                                                                                                                                                                                  1\n",
      "stillloveyatho                                                                                                                                                                                                                  1\n",
      "atiquetes                                                                                                                                                                                                                       1\n",
      "httpstcoopehvbbv                                                                                                                                                                                                                1\n",
      "httpstcojppabjpf                                                                                                                                                                                                                1\n",
      "“darling”                                                                                                                                                                                                                       1\n",
      "Length: 100, dtype: int64 \n",
      "RARE Y: \n",
      " たくさんご利用いただきありがとうございました！😍                                                                                                       1\n",
      "fubar                                                                                                                          1\n",
      "httpstcoabpoqxb                                                                                                                1\n",
      "customeras                                                                                                                     1\n",
      "downstream                                                                                                                     1\n",
      "ご心配をおかけしております。お届け予定日を経過している場合、お手数ですがamazon発送の場合→httpstcojyeizoqc、出品者発送の場合→httpstcozxcxcbntv                                    1\n",
      "safa                                                                                                                           1\n",
      "httpstcolwlygjci                                                                                                               1\n",
      "httpstcoltpakecglu                                                                                                             1\n",
      "😈ｷﾞﾗﾝ                                                                                                                          1\n",
      "httpstcolixqgmj                                                                                                                1\n",
      "httpstcoblwrjlzen                                                                                                              1\n",
      "httpstcoskxsbrug                                                                                                               1\n",
      "httpstcogdviydq                                                                                                                1\n",
      "lakeidra                                                                                                                       1\n",
      "family❤️                                                                                                                       1\n",
      "confirmationfr                                                                                                                 1\n",
      "amazonプライム無料体験をご利用ではありませんか？その場合、自動更新設定をオフにしていないと日後に有料会員へ移行します。無料体験申し込み時にeメールでお知らせをお送りしていますのでご確認下さい。分かりづらい点があり、申し訳ございませんでした。    1\n",
      "shev                                                                                                                           1\n",
      "httpstcowtwxwkheal                                                                                                             1\n",
      "httpstcongfoundcc                                                                                                              1\n",
      "continuo                                                                                                                       1\n",
      "bolehgtgt                                                                                                                      1\n",
      "httpstcooxhicvmz                                                                                                               1\n",
      "parcelhttpstcoepauizdbb                                                                                                        1\n",
      "httpstcopshkglq                                                                                                                1\n",
      "httpstcoyeuufvje                                                                                                               1\n",
      "gtgthttpstcoajmpfqqm                                                                                                           1\n",
      "melons                                                                                                                         1\n",
      "httpstcotszjbnkv                                                                                                               1\n",
      "                                                                                                                              ..\n",
      "fisco                                                                                                                          1\n",
      "expeditious                                                                                                                    1\n",
      "httpstcosnuhpgux                                                                                                               1\n",
      "ご心配をおかけしております。amazon発送の場合、ご注文の状況を確認させていただきます。お手数ですが以下リンクよりカスタマーサービスにご連絡ください。httpstcojyeizoqc                                   1\n",
      "httpstcoyffyuvgk                                                                                                               1\n",
      "piti                                                                                                                           1\n",
      "httpstcoymdxhsgxp                                                                                                              1\n",
      "subhasis                                                                                                                       1\n",
      "stickが見れないというのは、どのような状況でしょうか。一般的なトラブルシューティングを記載したヘルプがございますので、ご参照ください。httpstcopbgqjh                                            1\n",
      "httpstcoovhtiytwj                                                                                                              1\n",
      "httpstcogxgqfmllsc                                                                                                             1\n",
      "festlegen                                                                                                                      1\n",
      "httpstcozlruzrmuz                                                                                                              1\n",
      "httpstcoysgfrtbzwm                                                                                                             1\n",
      "httpstcofzgcwmvuc                                                                                                              1\n",
      "httpstcoteaayhydg                                                                                                              1\n",
      "httpstconmzlhhlq                                                                                                               1\n",
      "yew                                                                                                                            1\n",
      "httpstcodoxzdqwsj                                                                                                              1\n",
      "adeniyi                                                                                                                        1\n",
      "httpstconelrmvehrw                                                                                                             1\n",
      "melva                                                                                                                          1\n",
      "rhythm                                                                                                                         1\n",
      "ryon                                                                                                                           1\n",
      "nachträglicher                                                                                                                 1\n",
      "moneycardvia                                                                                                                   1\n",
      "httpstcozuzomdnfj                                                                                                              1\n",
      "vanita                                                                                                                         1\n",
      "httpstcolpsfmsz                                                                                                                1\n",
      "httpstcojpvmiqk                                                                                                                1\n",
      "Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "rareX = pd.Series(' '.join(inbOutb['text_x_clean']).split()).value_counts()[-100:]\n",
    "rareY = pd.Series(' '.join(inbOutb['text_y_clean']).split()).value_counts()[-100:]\n",
    "print('RARE X: \\n',rareX,'\\nRARE Y: \\n', rareY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing them\n",
    "rareX = list(rareX.index)\n",
    "rareY = list(rareY.index)\n",
    "inbOutb['text_x_clean'] = inbOutb['text_x_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in rareX))\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in rareY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing separates text into units such as sentences or words. It gives structure to previously unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to Tokenize words\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text) #W+ means that either a word character (A-Za-z0-9_) or a dash (-) can go there.\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbOutb['text_x_tokenized'] = inbOutb['text_x_clean'].apply(lambda x: tokenize(x.lower())) \n",
    "inbOutb['text_y_tokenized'] = inbOutb['text_y_clean'].apply(lambda x: tokenize(x.lower()))\n",
    "#We convert to lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_x_tokenized</th>\n",
       "      <th>text_y_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538902</th>\n",
       "      <td>568875</td>\n",
       "      <td>Wed Oct 18 09:54:26 +0000 2017</td>\n",
       "      <td>Hey @GloCare your LTE data service is becoming...</td>\n",
       "      <td>glocare</td>\n",
       "      <td>Wed Oct 18 13:08:38 +0000 2017</td>\n",
       "      <td>@568875 Afternoon Tari, may we know the exact ...</td>\n",
       "      <td>hey your lte data service becoming terrible do...</td>\n",
       "      <td>afternoon tari may know exact issue being expe...</td>\n",
       "      <td>afternoon tari may know exact issue experience...</td>\n",
       "      <td>[hey, your, lte, data, service, becoming, terr...</td>\n",
       "      <td>[afternoon, tari, may, know, exact, issue, bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127066</th>\n",
       "      <td>230636</td>\n",
       "      <td>Fri Dec 01 14:34:28 +0000 2017</td>\n",
       "      <td>If I can’t access tracking, how will I know wh...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 15:05:00 +0000 2017</td>\n",
       "      <td>@230636 Apologies for the concern, Stephanie! ...</td>\n",
       "      <td>if can’t access tracking how will know when th...</td>\n",
       "      <td>apologies concern stephanie could please confi...</td>\n",
       "      <td>apologies concern stephanie could please confi...</td>\n",
       "      <td>[if, can, t, access, tracking, how, will, know...</td>\n",
       "      <td>[apologies, concern, stephanie, could, please,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132865</th>\n",
       "      <td>236039</td>\n",
       "      <td>Fri Dec 01 20:57:53 +0000 2017</td>\n",
       "      <td>soooo glad i pay for amazon prime for my packa...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 20:59:40 +0000 2017</td>\n",
       "      <td>@236039 Did we miss the delivery date in the c...</td>\n",
       "      <td>soooo glad pay amazon prime package take days not</td>\n",
       "      <td>did miss delivery date in confirmation email c...</td>\n",
       "      <td>miss delivery date confirmation email check ht...</td>\n",
       "      <td>[soooo, glad, pay, amazon, prime, package, tak...</td>\n",
       "      <td>[did, miss, delivery, date, in, confirmation, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "538902      568875  Wed Oct 18 09:54:26 +0000 2017   \n",
       "127066      230636  Fri Dec 01 14:34:28 +0000 2017   \n",
       "132865      236039  Fri Dec 01 20:57:53 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "538902  Hey @GloCare your LTE data service is becoming...     glocare   \n",
       "127066  If I can’t access tracking, how will I know wh...  amazonhelp   \n",
       "132865  soooo glad i pay for amazon prime for my packa...  amazonhelp   \n",
       "\n",
       "                          created_at_y  \\\n",
       "538902  Wed Oct 18 13:08:38 +0000 2017   \n",
       "127066  Fri Dec 01 15:05:00 +0000 2017   \n",
       "132865  Fri Dec 01 20:59:40 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "538902  @568875 Afternoon Tari, may we know the exact ...   \n",
       "127066  @230636 Apologies for the concern, Stephanie! ...   \n",
       "132865  @236039 Did we miss the delivery date in the c...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "538902  hey your lte data service becoming terrible do...   \n",
       "127066  if can’t access tracking how will know when th...   \n",
       "132865  soooo glad pay amazon prime package take days not   \n",
       "\n",
       "                                             text_y_clean  \\\n",
       "538902  afternoon tari may know exact issue being expe...   \n",
       "127066  apologies concern stephanie could please confi...   \n",
       "132865  did miss delivery date in confirmation email c...   \n",
       "\n",
       "                                             text_wo_stop  \\\n",
       "538902  afternoon tari may know exact issue experience...   \n",
       "127066  apologies concern stephanie could please confi...   \n",
       "132865  miss delivery date confirmation email check ht...   \n",
       "\n",
       "                                         text_x_tokenized  \\\n",
       "538902  [hey, your, lte, data, service, becoming, terr...   \n",
       "127066  [if, can, t, access, tracking, how, will, know...   \n",
       "132865  [soooo, glad, pay, amazon, prime, package, tak...   \n",
       "\n",
       "                                         text_y_tokenized  \n",
       "538902  [afternoon, tari, may, know, exact, issue, bei...  \n",
       "127066  [apologies, concern, stephanie, could, please,...  \n",
       "132865  [did, miss, delivery, date, in, confirmation, ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Remove StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords are common words that will likely appear in any text. They don’t tell us much about our data so we remove them. eg: silver or lead is fine for me-> silver, lead, fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english') # All English Stopwords\n",
    "\n",
    "# Function to remove Stopwords\n",
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]# To remove all stopwords\n",
    "    return text\n",
    "\n",
    "inbOutb['text_x_tokenized'] = inbOutb['text_x_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "inbOutb['text_y_tokenized'] = inbOutb['text_y_tokenized'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_x_tokenized</th>\n",
       "      <th>text_y_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538902</th>\n",
       "      <td>568875</td>\n",
       "      <td>Wed Oct 18 09:54:26 +0000 2017</td>\n",
       "      <td>Hey @GloCare your LTE data service is becoming...</td>\n",
       "      <td>glocare</td>\n",
       "      <td>Wed Oct 18 13:08:38 +0000 2017</td>\n",
       "      <td>@568875 Afternoon Tari, may we know the exact ...</td>\n",
       "      <td>hey your lte data service becoming terrible do...</td>\n",
       "      <td>afternoon tari may know exact issue being expe...</td>\n",
       "      <td>afternoon tari may know exact issue experience...</td>\n",
       "      <td>[hey, lte, data, service, becoming, terrible, ...</td>\n",
       "      <td>[afternoon, tari, may, know, exact, issue, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127066</th>\n",
       "      <td>230636</td>\n",
       "      <td>Fri Dec 01 14:34:28 +0000 2017</td>\n",
       "      <td>If I can’t access tracking, how will I know wh...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 15:05:00 +0000 2017</td>\n",
       "      <td>@230636 Apologies for the concern, Stephanie! ...</td>\n",
       "      <td>if can’t access tracking how will know when th...</td>\n",
       "      <td>apologies concern stephanie could please confi...</td>\n",
       "      <td>apologies concern stephanie could please confi...</td>\n",
       "      <td>[access, tracking, know, arrived, arrive, got,...</td>\n",
       "      <td>[apologies, concern, stephanie, could, please,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132865</th>\n",
       "      <td>236039</td>\n",
       "      <td>Fri Dec 01 20:57:53 +0000 2017</td>\n",
       "      <td>soooo glad i pay for amazon prime for my packa...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 20:59:40 +0000 2017</td>\n",
       "      <td>@236039 Did we miss the delivery date in the c...</td>\n",
       "      <td>soooo glad pay amazon prime package take days not</td>\n",
       "      <td>did miss delivery date in confirmation email c...</td>\n",
       "      <td>miss delivery date confirmation email check ht...</td>\n",
       "      <td>[soooo, glad, pay, amazon, prime, package, tak...</td>\n",
       "      <td>[miss, delivery, date, confirmation, email, ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "538902      568875  Wed Oct 18 09:54:26 +0000 2017   \n",
       "127066      230636  Fri Dec 01 14:34:28 +0000 2017   \n",
       "132865      236039  Fri Dec 01 20:57:53 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "538902  Hey @GloCare your LTE data service is becoming...     glocare   \n",
       "127066  If I can’t access tracking, how will I know wh...  amazonhelp   \n",
       "132865  soooo glad i pay for amazon prime for my packa...  amazonhelp   \n",
       "\n",
       "                          created_at_y  \\\n",
       "538902  Wed Oct 18 13:08:38 +0000 2017   \n",
       "127066  Fri Dec 01 15:05:00 +0000 2017   \n",
       "132865  Fri Dec 01 20:59:40 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "538902  @568875 Afternoon Tari, may we know the exact ...   \n",
       "127066  @230636 Apologies for the concern, Stephanie! ...   \n",
       "132865  @236039 Did we miss the delivery date in the c...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "538902  hey your lte data service becoming terrible do...   \n",
       "127066  if can’t access tracking how will know when th...   \n",
       "132865  soooo glad pay amazon prime package take days not   \n",
       "\n",
       "                                             text_y_clean  \\\n",
       "538902  afternoon tari may know exact issue being expe...   \n",
       "127066  apologies concern stephanie could please confi...   \n",
       "132865  did miss delivery date in confirmation email c...   \n",
       "\n",
       "                                             text_wo_stop  \\\n",
       "538902  afternoon tari may know exact issue experience...   \n",
       "127066  apologies concern stephanie could please confi...   \n",
       "132865  miss delivery date confirmation email check ht...   \n",
       "\n",
       "                                         text_x_tokenized  \\\n",
       "538902  [hey, lte, data, service, becoming, terrible, ...   \n",
       "127066  [access, tracking, know, arrived, arrive, got,...   \n",
       "132865  [soooo, glad, pay, amazon, prime, package, tak...   \n",
       "\n",
       "                                         text_y_tokenized  \n",
       "538902  [afternoon, tari, may, know, exact, issue, exp...  \n",
       "127066  [apologies, concern, stephanie, could, please,...  \n",
       "132865  [miss, delivery, date, confirmation, email, ch...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tokenizing separates text into units such as sentences or words. It gives structure to previously unstructured text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming helps reduce a word to its stem form. It often makes sense to treat related words in the same way. It removes suffices, like “ing”, “ly”, “s”, etc. by a simple rule-based approach.\n",
    "It reduces the corpus of words but often the actual words get neglected. eg: Entitling,Entitled->Entitl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inbOutb['text_x_stemmed'] = inbOutb['text_x_nostop'].apply(lambda x: stemming(x))\n",
    "# inbOutb['text_y_stemmed'] = inbOutb['text_y_nostop'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing derives the canonical form (‘lemma’) of a word. i.e the root form. It is better than stemming as it uses a dictionary-based approach i.e a morphological analysis to the root word.eg: Entitling, Entitled->Entitle <br>\n",
    "In Short, Stemming is typically faster as it simply chops off the end of the word, without understanding the context of the word. Lemmatizing is slower and more accurate as it takes an informed analysis with the context of the word in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbOutb['text_x_lemmatized'] = inbOutb['text_x_tokenized'].apply(lambda x: lemmatizing(x))\n",
    "inbOutb['text_y_lemmatized'] = inbOutb['text_y_tokenized'].apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_x_tokenized</th>\n",
       "      <th>text_y_tokenized</th>\n",
       "      <th>text_x_lemmatized</th>\n",
       "      <th>text_y_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538902</th>\n",
       "      <td>568875</td>\n",
       "      <td>Wed Oct 18 09:54:26 +0000 2017</td>\n",
       "      <td>Hey @GloCare your LTE data service is becoming...</td>\n",
       "      <td>glocare</td>\n",
       "      <td>Wed Oct 18 13:08:38 +0000 2017</td>\n",
       "      <td>@568875 Afternoon Tari, may we know the exact ...</td>\n",
       "      <td>hey your lte data service becoming terrible do...</td>\n",
       "      <td>afternoon tari may know exact issue being expe...</td>\n",
       "      <td>afternoon tari may know exact issue experience...</td>\n",
       "      <td>[hey, lte, data, service, becoming, terrible, ...</td>\n",
       "      <td>[afternoon, tari, may, know, exact, issue, exp...</td>\n",
       "      <td>[hey, lte, data, service, becoming, terrible, ...</td>\n",
       "      <td>[afternoon, tari, may, know, exact, issue, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127066</th>\n",
       "      <td>230636</td>\n",
       "      <td>Fri Dec 01 14:34:28 +0000 2017</td>\n",
       "      <td>If I can’t access tracking, how will I know wh...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 15:05:00 +0000 2017</td>\n",
       "      <td>@230636 Apologies for the concern, Stephanie! ...</td>\n",
       "      <td>if can’t access tracking how will know when th...</td>\n",
       "      <td>apologies concern stephanie could please confi...</td>\n",
       "      <td>apologies concern stephanie could please confi...</td>\n",
       "      <td>[access, tracking, know, arrived, arrive, got,...</td>\n",
       "      <td>[apologies, concern, stephanie, could, please,...</td>\n",
       "      <td>[access, tracking, know, arrived, arrive, got,...</td>\n",
       "      <td>[apology, concern, stephanie, could, please, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132865</th>\n",
       "      <td>236039</td>\n",
       "      <td>Fri Dec 01 20:57:53 +0000 2017</td>\n",
       "      <td>soooo glad i pay for amazon prime for my packa...</td>\n",
       "      <td>amazonhelp</td>\n",
       "      <td>Fri Dec 01 20:59:40 +0000 2017</td>\n",
       "      <td>@236039 Did we miss the delivery date in the c...</td>\n",
       "      <td>soooo glad pay amazon prime package take days not</td>\n",
       "      <td>did miss delivery date in confirmation email c...</td>\n",
       "      <td>miss delivery date confirmation email check ht...</td>\n",
       "      <td>[soooo, glad, pay, amazon, prime, package, tak...</td>\n",
       "      <td>[miss, delivery, date, confirmation, email, ch...</td>\n",
       "      <td>[soooo, glad, pay, amazon, prime, package, tak...</td>\n",
       "      <td>[miss, delivery, date, confirmation, email, ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "538902      568875  Wed Oct 18 09:54:26 +0000 2017   \n",
       "127066      230636  Fri Dec 01 14:34:28 +0000 2017   \n",
       "132865      236039  Fri Dec 01 20:57:53 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "538902  Hey @GloCare your LTE data service is becoming...     glocare   \n",
       "127066  If I can’t access tracking, how will I know wh...  amazonhelp   \n",
       "132865  soooo glad i pay for amazon prime for my packa...  amazonhelp   \n",
       "\n",
       "                          created_at_y  \\\n",
       "538902  Wed Oct 18 13:08:38 +0000 2017   \n",
       "127066  Fri Dec 01 15:05:00 +0000 2017   \n",
       "132865  Fri Dec 01 20:59:40 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "538902  @568875 Afternoon Tari, may we know the exact ...   \n",
       "127066  @230636 Apologies for the concern, Stephanie! ...   \n",
       "132865  @236039 Did we miss the delivery date in the c...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "538902  hey your lte data service becoming terrible do...   \n",
       "127066  if can’t access tracking how will know when th...   \n",
       "132865  soooo glad pay amazon prime package take days not   \n",
       "\n",
       "                                             text_y_clean  \\\n",
       "538902  afternoon tari may know exact issue being expe...   \n",
       "127066  apologies concern stephanie could please confi...   \n",
       "132865  did miss delivery date in confirmation email c...   \n",
       "\n",
       "                                             text_wo_stop  \\\n",
       "538902  afternoon tari may know exact issue experience...   \n",
       "127066  apologies concern stephanie could please confi...   \n",
       "132865  miss delivery date confirmation email check ht...   \n",
       "\n",
       "                                         text_x_tokenized  \\\n",
       "538902  [hey, lte, data, service, becoming, terrible, ...   \n",
       "127066  [access, tracking, know, arrived, arrive, got,...   \n",
       "132865  [soooo, glad, pay, amazon, prime, package, tak...   \n",
       "\n",
       "                                         text_y_tokenized  \\\n",
       "538902  [afternoon, tari, may, know, exact, issue, exp...   \n",
       "127066  [apologies, concern, stephanie, could, please,...   \n",
       "132865  [miss, delivery, date, confirmation, email, ch...   \n",
       "\n",
       "                                        text_x_lemmatized  \\\n",
       "538902  [hey, lte, data, service, becoming, terrible, ...   \n",
       "127066  [access, tracking, know, arrived, arrive, got,...   \n",
       "132865  [soooo, glad, pay, amazon, prime, package, tak...   \n",
       "\n",
       "                                        text_y_lemmatized  \n",
       "538902  [afternoon, tari, may, know, exact, issue, exp...  \n",
       "127066  [apology, concern, stephanie, could, please, c...  \n",
       "132865  [miss, delivery, date, confirmation, email, ch...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inbOutb.to_csv('inbOutb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the library with the CountVectorizer method\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "questions = inbOutb['text_x_clean'].dropna()\n",
    "q = np.array(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Questions:  (794299, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Initialise the count vectorizer with the English stop words\n",
    "countV = CountVectorizer(stop_words='english',\n",
    "                         max_features=10000)\n",
    "\n",
    "# Fit and transform the processed titles\n",
    "bagQuestions = countV.fit_transform(q)\n",
    "\n",
    "print('BOW Questions: ',bagQuestions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordcloud with the most common words in customer requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Positive Vs Negative Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tweets = pd.read_csv('twcs.csv')\n",
    "inbound_tweets = tweets[tweets.inbound == True]\n",
    "inbound_tweets['timestamp'] = pd.to_datetime(inbound_tweets['created_at']).dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Explore the dataset for inbound tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2017-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:04:47 +0000 2017</td>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "      <td>11,13,14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2017-10-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id author_id  inbound                      created_at  \\\n",
       "1         2    115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3    115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "4         5    115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "6         8    115712     True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "8        12    115713     True  Tue Oct 31 22:04:47 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "6          @sprintcare is the worst customer service            9,6,10   \n",
       "8  @sprintcare You gonna magically change your co...          11,13,14   \n",
       "\n",
       "   in_response_to_tweet_id   timestamp  \n",
       "1                      1.0  2017-10-31  \n",
       "2                      4.0  2017-10-31  \n",
       "4                      6.0  2017-10-31  \n",
       "6                      NaN  2017-10-31  \n",
       "8                     15.0  2017-10-31  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'author_id', 'inbound', 'created_at', 'text',\n",
       "       'response_tweet_id', 'in_response_to_tweet_id', 'timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(inbound_tweets.head())\n",
    "display(inbound_tweets.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Collect quantities by author:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_author_id = inbound_tweets.groupby(['author_id']) \\\n",
    "    .count()[['tweet_id']] \\\n",
    "    .sort_values(['tweet_id'], ascending = False) \\\n",
    "    .rename({'tweet_id': 'qty'}, axis='columns')\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(count_by_author_id.index.values)), count_by_author_id.qty )\n",
    "plt.xlabel('Author #')\n",
    "plt.ylabel('Tweets Qty.')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Quantities by Date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_date = inbound_tweets.groupby(['timestamp']) \\\n",
    "    .count()[['tweet_id']] \\\n",
    "    .sort_values(['timestamp'], ascending = True) \\\n",
    "    .rename({'tweet_id': 'qty'}, axis='columns')\n",
    "\n",
    "display(count_by_date.head())\n",
    "plt.figure()\n",
    "plt.plot(count_by_date.index.values, count_by_date.qty )\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Tweets Qty.')\n",
    "plt.grid(True)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Process the sentiment analysis using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "inbound_tweets['score'] = inbound_tweets.text.apply(lambda x: sentiment_analyzer.polarity_scores(x)['compound'])\n",
    "display(inbound_tweets.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Check the Sentiment Analysis with an histogram of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_bins = 30\n",
    "plt.figure(figsize=[10,5])\n",
    "x = inbound_tweets[['score']]\n",
    "scores_hist,edges = np.histogram(x, bins=hist_bins)\n",
    "plt.bar(edges[:-1], scores_hist)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Tweets Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 Define limit for Pos. vs Neg. comment and compute results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_pos = 0.5\n",
    "limit_neg = -0.5\n",
    "limit_neg_per_author = 3\n",
    "#plt.plot(inbound_tweets.index.values, inbound_tweets['score'], 'r')\n",
    "#plt.axhline(0.5, 'g.')\n",
    "inbound_tweets['is_pos'] = (inbound_tweets[['score']] > limit_pos)\n",
    "inbound_tweets['is_neg'] = (inbound_tweets[['score']] < limit_neg)\n",
    "inbound_tweets['is_other'] = ~inbound_tweets.is_pos & ~inbound_tweets.is_neg\n",
    "\n",
    "def count_true(x):\n",
    "    return np.sum(x == True)\n",
    "\n",
    "scores_by_date = inbound_tweets.groupby(['timestamp']) \\\n",
    "    .agg({'tweet_id':'count', 'is_pos': count_true, 'is_neg': count_true, 'is_other': count_true}) \\\n",
    "    .rename({'tweet_id':'total'}, axis='columns')\n",
    "display(scores_by_date.head())\n",
    "x = scores_by_date.index.values\n",
    "y1 = scores_by_date['is_pos']\n",
    "y2 = scores_by_date['is_neg']\n",
    "\n",
    "scores_by_author = inbound_tweets.groupby(['author_id']) \\\n",
    "    .agg({'tweet_id':'count','is_neg': count_true}) \\\n",
    "    .rename({'tweet_id':'total'}, axis='columns')\n",
    "scores_by_author = scores_by_author.loc[scores_by_author['is_neg'] >= limit_neg_per_author]\n",
    "display(scores_by_author.head())\n",
    "\n",
    "#plt.scatter(x, y, alpha=0.5)\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.plot(x, y1,'g-', x, y2, 'r--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Qty.')\n",
    "plt.legend(['Pos.Tweet', 'Neg.Tweet'])\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
