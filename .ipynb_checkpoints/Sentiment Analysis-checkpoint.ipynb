{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li>The inbound feature is important because it allows you to distinguish between company and customer.</li>\n",
    "<li>Obviously the 'text' function is the main source of information.</li>\n",
    "<li>I will apply natural language processing techniques. In my opinion, it is possible to address the problem in two ways:</li>\n",
    "    <ul><li>Catalog customer tweets and identify the most discussed topics;</li>\n",
    "        <li>Create a model that adapts to the tweets of the companies and try to answer a specific topic of a customer (to do)</li></ul>\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Geting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twcs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195711</th>\n",
       "      <td>230120</td>\n",
       "      <td>170830</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 04 19:00:53 +0000 2017</td>\n",
       "      <td>@AmazonHelp Already marked a email but you guy...</td>\n",
       "      <td>230118,230121,230122</td>\n",
       "      <td>230123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203956</th>\n",
       "      <td>238736</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 04 18:25:09 +0000 2017</td>\n",
       "      <td>@172787 Ideally it should have happened by now...</td>\n",
       "      <td>238737</td>\n",
       "      <td>238738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738949</th>\n",
       "      <td>825747</td>\n",
       "      <td>ChaseSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 18 01:22:58 +0000 2017</td>\n",
       "      <td>@160010 Please DM your full name and zip code,...</td>\n",
       "      <td>825748</td>\n",
       "      <td>825746.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745275</th>\n",
       "      <td>832893</td>\n",
       "      <td>219463</td>\n",
       "      <td>True</td>\n",
       "      <td>Fri Oct 13 07:33:31 +0000 2017</td>\n",
       "      <td>@AmazonHelp Eure Reaktion erklaert, warum die ...</td>\n",
       "      <td>832894</td>\n",
       "      <td>832892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248421</th>\n",
       "      <td>1377772</td>\n",
       "      <td>Uber_Support</td>\n",
       "      <td>False</td>\n",
       "      <td>Sat Oct 28 03:17:47 +0000 2017</td>\n",
       "      <td>@440746 Here to help! Send us a note here, htt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377773.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841527</th>\n",
       "      <td>1998603</td>\n",
       "      <td>AirbnbHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>Fri Nov 03 19:20:20 +0000 2017</td>\n",
       "      <td>@590946 We want to help with this cancellation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091642</th>\n",
       "      <td>1207672</td>\n",
       "      <td>403562</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 25 09:14:06 +0000 2017</td>\n",
       "      <td>@SpotifyCares Can I have some help about stopp...</td>\n",
       "      <td>1207671</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344108</th>\n",
       "      <td>2510790</td>\n",
       "      <td>AskPlayStation</td>\n",
       "      <td>False</td>\n",
       "      <td>Mon Oct 30 04:49:57 +0000 2017</td>\n",
       "      <td>@715674 Hi there. Glad to help! Please check y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2510791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562239</th>\n",
       "      <td>2733137</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Mon Nov 20 16:20:06 +0000 2017</td>\n",
       "      <td>@561268 You will be contacted. Team @116447</td>\n",
       "      <td>2733138,2733139</td>\n",
       "      <td>2733140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241614</th>\n",
       "      <td>279371</td>\n",
       "      <td>182606</td>\n",
       "      <td>True</td>\n",
       "      <td>Mon Oct 09 22:47:00 +0000 2017</td>\n",
       "      <td>@AmazonHelp  https://t.co/nojv3hwcA9</td>\n",
       "      <td>279372</td>\n",
       "      <td>279370.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id       author_id  inbound                      created_at  \\\n",
       "195711     230120          170830     True  Wed Oct 04 19:00:53 +0000 2017   \n",
       "203956     238736      AmazonHelp    False  Wed Oct 04 18:25:09 +0000 2017   \n",
       "738949     825747    ChaseSupport    False  Wed Oct 18 01:22:58 +0000 2017   \n",
       "745275     832893          219463     True  Fri Oct 13 07:33:31 +0000 2017   \n",
       "1248421   1377772    Uber_Support    False  Sat Oct 28 03:17:47 +0000 2017   \n",
       "1841527   1998603      AirbnbHelp    False  Fri Nov 03 19:20:20 +0000 2017   \n",
       "1091642   1207672          403562     True  Wed Oct 25 09:14:06 +0000 2017   \n",
       "2344108   2510790  AskPlayStation    False  Mon Oct 30 04:49:57 +0000 2017   \n",
       "2562239   2733137      sprintcare    False  Mon Nov 20 16:20:06 +0000 2017   \n",
       "241614     279371          182606     True  Mon Oct 09 22:47:00 +0000 2017   \n",
       "\n",
       "                                                      text  \\\n",
       "195711   @AmazonHelp Already marked a email but you guy...   \n",
       "203956   @172787 Ideally it should have happened by now...   \n",
       "738949   @160010 Please DM your full name and zip code,...   \n",
       "745275   @AmazonHelp Eure Reaktion erklaert, warum die ...   \n",
       "1248421  @440746 Here to help! Send us a note here, htt...   \n",
       "1841527  @590946 We want to help with this cancellation...   \n",
       "1091642  @SpotifyCares Can I have some help about stopp...   \n",
       "2344108  @715674 Hi there. Glad to help! Please check y...   \n",
       "2562239        @561268 You will be contacted. Team @116447   \n",
       "241614                @AmazonHelp  https://t.co/nojv3hwcA9   \n",
       "\n",
       "            response_tweet_id  in_response_to_tweet_id  \n",
       "195711   230118,230121,230122                 230123.0  \n",
       "203956                 238737                 238738.0  \n",
       "738949                 825748                 825746.0  \n",
       "745275                 832894                 832892.0  \n",
       "1248421                   NaN                1377773.0  \n",
       "1841527                   NaN                1998604.0  \n",
       "1091642               1207671                      NaN  \n",
       "2344108                   NaN                2510791.0  \n",
       "2562239       2733138,2733139                2733140.0  \n",
       "241614                 279372                 279370.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2811774, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2811774 entries, 0 to 2811773\n",
      "Data columns (total 7 columns):\n",
      "tweet_id                   int64\n",
      "author_id                  object\n",
      "inbound                    bool\n",
      "created_at                 object\n",
      "text                       object\n",
      "response_tweet_id          object\n",
      "in_response_to_tweet_id    float64\n",
      "dtypes: bool(1), float64(1), int64(1), object(4)\n",
      "memory usage: 131.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Checking missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                         0\n",
       "author_id                        0\n",
       "inbound                          0\n",
       "created_at                       0\n",
       "text                             0\n",
       "response_tweet_id          1040629\n",
       "in_response_to_tweet_id     794335\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first inbound = Richiesta iniziale di un cliente\n",
    "first_inbound = df[pd.isnull(df.in_response_to_tweet_id) & df.inbound]\n",
    "\n",
    "inbOutb = pd.merge(first_inbound, df, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id').sample(frac=1)\n",
    "\n",
    "# Filter to only outbound replies (from companies)\n",
    "inbOutb = inbOutb[inbOutb.inbound_y ^ True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794299, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now the dataset is doubled in size (features), as each line contains:</b>\n",
    "<ul><li>a customer request (text_x)</li>\n",
    "    <li>a reply from the company (text_y)</li>\n",
    "    <li>Related related features</li></ul>\n",
    "\n",
    "<b>From which we can easily verify that:</b>\n",
    "<ul><li>the 'inbound_x' feature is always True;</li>\n",
    "    <li>the 'inbound_y' feature is always False;</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id_x                        0\n",
       "author_id_x                       0\n",
       "inbound_x                         0\n",
       "created_at_x                      0\n",
       "text_x                            0\n",
       "response_tweet_id_x               0\n",
       "in_response_to_tweet_id_x    794299\n",
       "tweet_id_y                        0\n",
       "author_id_y                       0\n",
       "inbound_y                         0\n",
       "created_at_y                      0\n",
       "text_y                            0\n",
       "response_tweet_id_y          530528\n",
       "in_response_to_tweet_id_y         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>'in_response_to_tweet_id_x'</b> feature is totally composed of <b>NaN.</b> So this feature will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Drop useless features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id_x', 'author_id_x', 'inbound_x', 'created_at_x', 'text_x',\n",
       "       'response_tweet_id_x', 'in_response_to_tweet_id_x', 'tweet_id_y',\n",
       "       'author_id_y', 'inbound_y', 'created_at_y', 'text_y',\n",
       "       'response_tweet_id_y', 'in_response_to_tweet_id_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "toDrop = ['tweet_id_x', 'inbound_x','response_tweet_id_x', 'in_response_to_tweet_id_x', \n",
    "          'tweet_id_y', 'inbound_y','response_tweet_id_y', 'in_response_to_tweet_id_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inbOutb shape:  (794299, 6)\n"
     ]
    }
   ],
   "source": [
    "inbOutb.drop(toDrop, axis=1, inplace=True)\n",
    "print('inbOutb shape: ', inbOutb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568464</th>\n",
       "      <td>591714</td>\n",
       "      <td>Fri Nov 03 15:33:42 +0000 2017</td>\n",
       "      <td>SMH dog IÔ∏è did that IÔ∏è in the keyboard shit an...</td>\n",
       "      <td>AppleSupport</td>\n",
       "      <td>Fri Nov 03 20:29:00 +0000 2017</td>\n",
       "      <td>@591714 We'd be happy to look into what's goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398372</th>\n",
       "      <td>456007</td>\n",
       "      <td>Thu Nov 02 14:42:57 +0000 2017</td>\n",
       "      <td>@117157 Why is you mobile app not working. I k...</td>\n",
       "      <td>AskCiti</td>\n",
       "      <td>Thu Nov 02 16:06:00 +0000 2017</td>\n",
       "      <td>@456007 Yes, sorry for this! Our app is having...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830506</th>\n",
       "      <td>790657</td>\n",
       "      <td>Mon Nov 27 15:57:29 +0000 2017</td>\n",
       "      <td>@ChipotleTweets should do breakfast.</td>\n",
       "      <td>ChipotleTweets</td>\n",
       "      <td>Mon Nov 27 16:15:00 +0000 2017</td>\n",
       "      <td>@790657 We are testing breakfast burritos in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346390</th>\n",
       "      <td>125004</td>\n",
       "      <td>Thu Oct 26 10:32:52 +0000 2017</td>\n",
       "      <td>@115722 @125004 Good morning New York ‚òÄÔ∏è</td>\n",
       "      <td>VerizonSupport</td>\n",
       "      <td>Thu Oct 26 10:37:26 +0000 2017</td>\n",
       "      <td>@125004 Good morning. \\n^TXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807747</th>\n",
       "      <td>773738</td>\n",
       "      <td>Mon Nov 20 15:36:03 +0000 2017</td>\n",
       "      <td>@DropboxSupport how do we reinstate an account...</td>\n",
       "      <td>DropboxSupport</td>\n",
       "      <td>Tue Nov 21 10:07:47 +0000 2017</td>\n",
       "      <td>@773738 ...ID, so as to look it up internally ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "568464      591714  Fri Nov 03 15:33:42 +0000 2017   \n",
       "398372      456007  Thu Nov 02 14:42:57 +0000 2017   \n",
       "830506      790657  Mon Nov 27 15:57:29 +0000 2017   \n",
       "346390      125004  Thu Oct 26 10:32:52 +0000 2017   \n",
       "807747      773738  Mon Nov 20 15:36:03 +0000 2017   \n",
       "\n",
       "                                                   text_x     author_id_y  \\\n",
       "568464  SMH dog IÔ∏è did that IÔ∏è in the keyboard shit an...    AppleSupport   \n",
       "398372  @117157 Why is you mobile app not working. I k...         AskCiti   \n",
       "830506               @ChipotleTweets should do breakfast.  ChipotleTweets   \n",
       "346390           @115722 @125004 Good morning New York ‚òÄÔ∏è  VerizonSupport   \n",
       "807747  @DropboxSupport how do we reinstate an account...  DropboxSupport   \n",
       "\n",
       "                          created_at_y  \\\n",
       "568464  Fri Nov 03 20:29:00 +0000 2017   \n",
       "398372  Thu Nov 02 16:06:00 +0000 2017   \n",
       "830506  Mon Nov 27 16:15:00 +0000 2017   \n",
       "346390  Thu Oct 26 10:37:26 +0000 2017   \n",
       "807747  Tue Nov 21 10:07:47 +0000 2017   \n",
       "\n",
       "                                                   text_y  \n",
       "568464  @591714 We'd be happy to look into what's goin...  \n",
       "398372  @456007 Yes, sorry for this! Our app is having...  \n",
       "830506  @790657 We are testing breakfast burritos in t...  \n",
       "346390                       @125004 Good morning. \\n^TXA  \n",
       "807747  @773738 ...ID, so as to look it up internally ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 794299 entries, 315288 to 671189\n",
      "Data columns (total 6 columns):\n",
      "author_id_x     794299 non-null object\n",
      "created_at_x    794299 non-null object\n",
      "text_x          794299 non-null object\n",
      "author_id_y     794299 non-null object\n",
      "created_at_y    794299 non-null object\n",
      "text_y          794299 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 42.4+ MB\n"
     ]
    }
   ],
   "source": [
    "inbOutb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794299, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Lower Casing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower casing is a common text preprocessing technique. The idea is to convert the input text into same casing format so that 'text', 'Text' and 'TEXT' are treated the same way.\n",
    "\n",
    "This is more helpful for text featurization techniques like frequency, tfidf as it helps to combine the same words together thereby reducing the duplication and get correct counts / tfidf values.\n",
    "\n",
    "This may not be helpful when we do tasks like Part of Speech tagging (where proper casing gives some information about Nouns and so on) and Sentiment Analysis (where upper casing refers to anger and so on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_uppercase(text):\n",
    "    text_lowercase = ' '.join(x.lower() for x in text.split())# It will discard all uppercases\n",
    "    return text_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbOutb['text_x_clean'] = inbOutb['text_x'].apply(lambda x: remove_uppercase(x))\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y'].apply(lambda x: remove_uppercase(x))\n",
    "#in modo da poter rimuovere i nomi delle compagnie\n",
    "inbOutb['author_id_y'] = inbOutb['author_id_y'].apply(lambda x: remove_uppercase(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315288</th>\n",
       "      <td>390987</td>\n",
       "      <td>Sat Oct 14 23:33:37 +0000 2017</td>\n",
       "      <td>@115879 how many times should the system cance...</td>\n",
       "      <td>asklyft</td>\n",
       "      <td>Sun Oct 15 00:57:16 +0000 2017</td>\n",
       "      <td>@390987 Hello! We are sorry to hear this. Can ...</td>\n",
       "      <td>@115879 how many times should the system cance...</td>\n",
       "      <td>@390987 hello! we are sorry to hear this. can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461149</th>\n",
       "      <td>507004</td>\n",
       "      <td>Sat Nov 04 20:52:57 +0000 2017</td>\n",
       "      <td>@ATVIAssist servers aren't working for me. Err...</td>\n",
       "      <td>atviassist</td>\n",
       "      <td>Mon Nov 06 09:34:53 +0000 2017</td>\n",
       "      <td>@507004 Apologies for the delay, things should...</td>\n",
       "      <td>@atviassist servers aren't working for me. err...</td>\n",
       "      <td>@507004 apologies for the delay, things should...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510666</th>\n",
       "      <td>547353</td>\n",
       "      <td>Sun Oct 15 14:58:01 +0000 2017</td>\n",
       "      <td>@AskTarget FYI, App was updated on 10/13 and i...</td>\n",
       "      <td>asktarget</td>\n",
       "      <td>Sun Oct 15 20:11:54 +0000 2017</td>\n",
       "      <td>@547353 Thank you for letting us know. Can you...</td>\n",
       "      <td>@asktarget fyi, app was updated on 10/13 and i...</td>\n",
       "      <td>@547353 thank you for letting us know. can you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "315288      390987  Sat Oct 14 23:33:37 +0000 2017   \n",
       "461149      507004  Sat Nov 04 20:52:57 +0000 2017   \n",
       "510666      547353  Sun Oct 15 14:58:01 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "315288  @115879 how many times should the system cance...     asklyft   \n",
       "461149  @ATVIAssist servers aren't working for me. Err...  atviassist   \n",
       "510666  @AskTarget FYI, App was updated on 10/13 and i...   asktarget   \n",
       "\n",
       "                          created_at_y  \\\n",
       "315288  Sun Oct 15 00:57:16 +0000 2017   \n",
       "461149  Mon Nov 06 09:34:53 +0000 2017   \n",
       "510666  Sun Oct 15 20:11:54 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "315288  @390987 Hello! We are sorry to hear this. Can ...   \n",
       "461149  @507004 Apologies for the delay, things should...   \n",
       "510666  @547353 Thank you for letting us know. Can you...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "315288  @115879 how many times should the system cance...   \n",
       "461149  @atviassist servers aren't working for me. err...   \n",
       "510666  @asktarget fyi, app was updated on 10/13 and i...   \n",
       "\n",
       "                                             text_y_clean  \n",
       "315288  @390987 hello! we are sorry to hear this. can ...  \n",
       "461149  @507004 apologies for the delay, things should...  \n",
       "510666  @547353 thank you for letting us know. can you...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Remove Puntuaction\n",
    "\n",
    "Punctuation can provide grammatical context to a sentence which supports our understanding. But for our vectorizer which counts the number of words and not the context, it does not add value, so we remove all special characters. eg: How are you?->How are you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315288</th>\n",
       "      <td>390987</td>\n",
       "      <td>Sat Oct 14 23:33:37 +0000 2017</td>\n",
       "      <td>@115879 how many times should the system cance...</td>\n",
       "      <td>asklyft</td>\n",
       "      <td>Sun Oct 15 00:57:16 +0000 2017</td>\n",
       "      <td>@390987 Hello! We are sorry to hear this. Can ...</td>\n",
       "      <td>115879 how many times should the system cancel...</td>\n",
       "      <td>390987 hello we are sorry to hear this can you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461149</th>\n",
       "      <td>507004</td>\n",
       "      <td>Sat Nov 04 20:52:57 +0000 2017</td>\n",
       "      <td>@ATVIAssist servers aren't working for me. Err...</td>\n",
       "      <td>atviassist</td>\n",
       "      <td>Mon Nov 06 09:34:53 +0000 2017</td>\n",
       "      <td>@507004 Apologies for the delay, things should...</td>\n",
       "      <td>atviassist servers arent working for me error ...</td>\n",
       "      <td>507004 apologies for the delay things should b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510666</th>\n",
       "      <td>547353</td>\n",
       "      <td>Sun Oct 15 14:58:01 +0000 2017</td>\n",
       "      <td>@AskTarget FYI, App was updated on 10/13 and i...</td>\n",
       "      <td>asktarget</td>\n",
       "      <td>Sun Oct 15 20:11:54 +0000 2017</td>\n",
       "      <td>@547353 Thank you for letting us know. Can you...</td>\n",
       "      <td>asktarget fyi app was updated on 1013 and is v...</td>\n",
       "      <td>547353 thank you for letting us know can you d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "315288      390987  Sat Oct 14 23:33:37 +0000 2017   \n",
       "461149      507004  Sat Nov 04 20:52:57 +0000 2017   \n",
       "510666      547353  Sun Oct 15 14:58:01 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "315288  @115879 how many times should the system cance...     asklyft   \n",
       "461149  @ATVIAssist servers aren't working for me. Err...  atviassist   \n",
       "510666  @AskTarget FYI, App was updated on 10/13 and i...   asktarget   \n",
       "\n",
       "                          created_at_y  \\\n",
       "315288  Sun Oct 15 00:57:16 +0000 2017   \n",
       "461149  Mon Nov 06 09:34:53 +0000 2017   \n",
       "510666  Sun Oct 15 20:11:54 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "315288  @390987 Hello! We are sorry to hear this. Can ...   \n",
       "461149  @507004 Apologies for the delay, things should...   \n",
       "510666  @547353 Thank you for letting us know. Can you...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "315288  115879 how many times should the system cancel...   \n",
       "461149  atviassist servers arent working for me error ...   \n",
       "510666  asktarget fyi app was updated on 1013 and is v...   \n",
       "\n",
       "                                             text_y_clean  \n",
       "315288  390987 hello we are sorry to hear this can you...  \n",
       "461149  507004 apologies for the delay things should b...  \n",
       "510666  547353 thank you for letting us know can you d...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to remove Punctuation\n",
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])# It will discard all punctuations\n",
    "    return text_nopunct\n",
    "inbOutb['text_x_clean'] = inbOutb['text_x_clean'].apply(lambda x: remove_punct(x))\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y_clean'].apply(lambda x: remove_punct(x))\n",
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Removing usernames\n",
    "rimuovere nomi utenti, compagnie da text_x_clean<br>\n",
    "rimuovere nomi utenti, compagnie da text_y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315288</th>\n",
       "      <td>390987</td>\n",
       "      <td>Sat Oct 14 23:33:37 +0000 2017</td>\n",
       "      <td>@115879 how many times should the system cance...</td>\n",
       "      <td>asklyft</td>\n",
       "      <td>Sun Oct 15 00:57:16 +0000 2017</td>\n",
       "      <td>@390987 Hello! We are sorry to hear this. Can ...</td>\n",
       "      <td>how many times should the system cancel or ch...</td>\n",
       "      <td>hello we are sorry to hear this can you dm us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461149</th>\n",
       "      <td>507004</td>\n",
       "      <td>Sat Nov 04 20:52:57 +0000 2017</td>\n",
       "      <td>@ATVIAssist servers aren't working for me. Err...</td>\n",
       "      <td>atviassist</td>\n",
       "      <td>Mon Nov 06 09:34:53 +0000 2017</td>\n",
       "      <td>@507004 Apologies for the delay, things should...</td>\n",
       "      <td>servers arent working for me error code  but ...</td>\n",
       "      <td>apologies for the delay things should be back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510666</th>\n",
       "      <td>547353</td>\n",
       "      <td>Sun Oct 15 14:58:01 +0000 2017</td>\n",
       "      <td>@AskTarget FYI, App was updated on 10/13 and i...</td>\n",
       "      <td>asktarget</td>\n",
       "      <td>Sun Oct 15 20:11:54 +0000 2017</td>\n",
       "      <td>@547353 Thank you for letting us know. Can you...</td>\n",
       "      <td>fyi app was updated on  and is version</td>\n",
       "      <td>thank you for letting us know can you dm us t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "315288      390987  Sat Oct 14 23:33:37 +0000 2017   \n",
       "461149      507004  Sat Nov 04 20:52:57 +0000 2017   \n",
       "510666      547353  Sun Oct 15 14:58:01 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "315288  @115879 how many times should the system cance...     asklyft   \n",
       "461149  @ATVIAssist servers aren't working for me. Err...  atviassist   \n",
       "510666  @AskTarget FYI, App was updated on 10/13 and i...   asktarget   \n",
       "\n",
       "                          created_at_y  \\\n",
       "315288  Sun Oct 15 00:57:16 +0000 2017   \n",
       "461149  Mon Nov 06 09:34:53 +0000 2017   \n",
       "510666  Sun Oct 15 20:11:54 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "315288  @390987 Hello! We are sorry to hear this. Can ...   \n",
       "461149  @507004 Apologies for the delay, things should...   \n",
       "510666  @547353 Thank you for letting us know. Can you...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "315288   how many times should the system cancel or ch...   \n",
       "461149   servers arent working for me error code  but ...   \n",
       "510666            fyi app was updated on  and is version    \n",
       "\n",
       "                                             text_y_clean  \n",
       "315288   hello we are sorry to hear this can you dm us...  \n",
       "461149   apologies for the delay things should be back...  \n",
       "510666   thank you for letting us know can you dm us t...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = inbOutb['author_id_y'].unique()\n",
    "\n",
    "inbOutb['text_x_clean'] = inbOutb['text_x_clean'].str.replace('\\d+', '')\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y_clean'].str.replace('\\d+', '')\n",
    "\n",
    "inbOutb['text_x_clean'] = inbOutb['text_x_clean'].str.replace('|'.join(companies), '')\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y_clean'].str.replace('|'.join(companies), '')\n",
    "\n",
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794299, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Removal of stopwords\n",
    "Stopwords are commonly occuring words in a language like 'the', 'a' and so on. They can be removed from the text most of the times, as they don't provide valuable information for downstream analysis. In cases like Part of Speech tagging, we should not remove them as provide very valuable information about the POS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Similarly we can also get the list for other languages as well and use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "      <th>text_wo_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315288</th>\n",
       "      <td>390987</td>\n",
       "      <td>Sat Oct 14 23:33:37 +0000 2017</td>\n",
       "      <td>@115879 how many times should the system cance...</td>\n",
       "      <td>asklyft</td>\n",
       "      <td>Sun Oct 15 00:57:16 +0000 2017</td>\n",
       "      <td>@390987 Hello! We are sorry to hear this. Can ...</td>\n",
       "      <td>how many times should the system cancel or ch...</td>\n",
       "      <td>hello we are sorry to hear this can you dm us...</td>\n",
       "      <td>hello sorry hear dm us phone number ached acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461149</th>\n",
       "      <td>507004</td>\n",
       "      <td>Sat Nov 04 20:52:57 +0000 2017</td>\n",
       "      <td>@ATVIAssist servers aren't working for me. Err...</td>\n",
       "      <td>atviassist</td>\n",
       "      <td>Mon Nov 06 09:34:53 +0000 2017</td>\n",
       "      <td>@507004 Apologies for the delay, things should...</td>\n",
       "      <td>servers arent working for me error code  but ...</td>\n",
       "      <td>apologies for the delay things should be back...</td>\n",
       "      <td>apologies delay things back still unable conne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510666</th>\n",
       "      <td>547353</td>\n",
       "      <td>Sun Oct 15 14:58:01 +0000 2017</td>\n",
       "      <td>@AskTarget FYI, App was updated on 10/13 and i...</td>\n",
       "      <td>asktarget</td>\n",
       "      <td>Sun Oct 15 20:11:54 +0000 2017</td>\n",
       "      <td>@547353 Thank you for letting us know. Can you...</td>\n",
       "      <td>fyi app was updated on  and is version</td>\n",
       "      <td>thank you for letting us know can you dm us t...</td>\n",
       "      <td>thank letting us know dm us date store locatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "315288      390987  Sat Oct 14 23:33:37 +0000 2017   \n",
       "461149      507004  Sat Nov 04 20:52:57 +0000 2017   \n",
       "510666      547353  Sun Oct 15 14:58:01 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "315288  @115879 how many times should the system cance...     asklyft   \n",
       "461149  @ATVIAssist servers aren't working for me. Err...  atviassist   \n",
       "510666  @AskTarget FYI, App was updated on 10/13 and i...   asktarget   \n",
       "\n",
       "                          created_at_y  \\\n",
       "315288  Sun Oct 15 00:57:16 +0000 2017   \n",
       "461149  Mon Nov 06 09:34:53 +0000 2017   \n",
       "510666  Sun Oct 15 20:11:54 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "315288  @390987 Hello! We are sorry to hear this. Can ...   \n",
       "461149  @507004 Apologies for the delay, things should...   \n",
       "510666  @547353 Thank you for letting us know. Can you...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "315288   how many times should the system cancel or ch...   \n",
       "461149   servers arent working for me error code  but ...   \n",
       "510666            fyi app was updated on  and is version    \n",
       "\n",
       "                                             text_y_clean  \\\n",
       "315288   hello we are sorry to hear this can you dm us...   \n",
       "461149   apologies for the delay things should be back...   \n",
       "510666   thank you for letting us know can you dm us t...   \n",
       "\n",
       "                                             text_wo_stop  \n",
       "315288  hello sorry hear dm us phone number ached acco...  \n",
       "461149  apologies delay things back still unable conne...  \n",
       "510666  thank letting us know dm us date store locatio...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "inbOutb['text_wo_stop'] = inbOutb['text_x_clean'].apply(lambda x: remove_stopwords(x))\n",
    "inbOutb['text_wo_stop'] = inbOutb['text_y_clean'].apply(lambda y: remove_stopwords(y))\n",
    "\n",
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5  Checking Most Common Worlds\n",
    "Previously, we just removed commonly occurring words in a general sense. We can also remove commonly occurring words from our text data First, let‚Äôs check the 10 most frequently occurring words in our text data then take call to remove or retain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ X: \n",
      " to     450771\n",
      "i      402429\n",
      "the    394086\n",
      "my     310607\n",
      "a      289704\n",
      "and    250549\n",
      "is     210765\n",
      "for    199934\n",
      "on     184365\n",
      "you    172960\n",
      "dtype: int64 \n",
      "FREQ Y: \n",
      " to      597010\n",
      "you     562841\n",
      "the     438571\n",
      "your    355927\n",
      "we      300935\n",
      "us      281678\n",
      "for     280735\n",
      "can     262541\n",
      "a       257072\n",
      "this    245768\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#common worlds\n",
    "\n",
    "freqX = pd.Series(' '.join(inbOutb['text_x_clean']).split()).value_counts()[:10]\n",
    "freqY = pd.Series(' '.join(inbOutb['text_y_clean']).split()).value_counts()[:10]\n",
    "print('FREQ X: \\n',freqX,'\\nFREQ Y: \\n', freqY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing them\n",
    "freqX = list(freqX.index)\n",
    "freqY = list(freqY.index)\n",
    "inbOutb['text_x_clean'] = inbOutb['text_x_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in freqX))\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in freqY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Checking Most Rare Worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RARE X: \n",
      " httpstcoklmsha             1\n",
      "inascratchika              1\n",
      "httpstcowtfxbssns          1\n",
      "httpstcouqzpqgfu           1\n",
      "mesti                      1\n",
      "httpstcoptmwmoyj           1\n",
      "playlistüò´                  1\n",
      "httpstcoollmmtg            1\n",
      "pokerfaceswimsuit          1\n",
      "httpstcoubfohsxu           1\n",
      "httpstcohverymivvz         1\n",
      "ondia                      1\n",
      "httpstcoujbvbgzp           1\n",
      "l‚Äôoccitane                 1\n",
      "httpstcommixmbev           1\n",
      "httpstcosaoetx             1\n",
      "httpstcocegdxglblo         1\n",
      "deviery                    1\n",
      "giftsforwomen              1\n",
      "gbwill                     1\n",
      "‚Äúgarlic‚Äù                   1\n",
      "httpstcongmpgeewwy         1\n",
      "swellingkeayboard          1\n",
      "undisclose                 1\n",
      "httpstcocdwhfamb           1\n",
      "httpstcojexaaknv           1\n",
      "nooooothing                1\n",
      "httpstcowvagjzt            1\n",
      "httpstcosenbpelim          1\n",
      "üé§üé§üé§                        1\n",
      "                          ..\n",
      "repurchase‚Ä¶                1\n",
      "httpstcosmyklmaaqi         1\n",
      "bellextremely              1\n",
      "httpstcorhnlnqqexl         1\n",
      "httpstcolidciwcgvb         1\n",
      "httpstcoaqqctevxr          1\n",
      "ü§òü§òü§ò                        1\n",
      "httpstcohudlgrd            1\n",
      "httpstcodqjuvwkoh          1\n",
      "httpstcoqmirz              1\n",
      "committers                 1\n",
      "httpstcodnzuszn            1\n",
      "httpstcopauibovia          1\n",
      "maradham                   1\n",
      "menacer                    1\n",
      "eigenprod                  1\n",
      "lz                         1\n",
      "settingsüò°                  1\n",
      "dryüò°                       1\n",
      "httpstcohdcwhmlc           1\n",
      "rulerofthefastfoodworld    1\n",
      "dontbequarkxpress          1\n",
      "badlydesigned              1\n",
      "gojorita                   1\n",
      "mailemail                  1\n",
      "httpstcoqdkykfwexg         1\n",
      "capnmilo                   1\n",
      "dremel                     1\n",
      "httpstcogwbdyyrh           1\n",
      "httpstcojforegik           1\n",
      "Length: 100, dtype: int64 \n",
      "RARE Y: \n",
      " herstellergarantie                                                                                                     1\n",
      "popolar                                                                                                                1\n",
      "„ÅîÊ≥®Êñá„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åó„ÅüÔºÅÔºà‰∏ÄÂ∫¶„Å´ÁÆ±„Çí‰∏Ä‰∫∫„ÅßÂÆåÈ£ü„Éª„Éª„Éª„Å™„Çè„Åë„Å™„ÅÑ„Åß„Åô„Çà„Å≠ÔºâooÔΩ°„Éæ¬¥‚ñΩÔΩÄa                                                                        1\n",
      "st√©phanie                                                                                                              1\n",
      "üåØüéä                                                                                                                     1\n",
      "needsh                                                                                                                 1\n",
      "httpstcotgkrkvhm                                                                                                       1\n",
      "httpstcokwktscsr                                                                                                       1\n",
      "jambokune                                                                                                              1\n",
      "victorine                                                                                                              1\n",
      "httpstcozouatyatr                                                                                                      1\n",
      "httpstcoejzotbyui                                                                                                      1\n",
      "httpstcodqevcswb                                                                                                       1\n",
      "httpstcoymwfwplpn                                                                                                      1\n",
      "httpstcoqxdkrwm                                                                                                        1\n",
      "–ø–æ—è–≤–∏–ª–∞—Å—å                                                                                                              1\n",
      "httpstcoslgljkz                                                                                                        1\n",
      "helpwal                                                                                                                1\n",
      "„Ç¢„Éû„Çæ„É≥ÂÖ¨Âºè„Åß„Åô„ÄÇ„ÅîË™çË≠ò„ÅÆÈÄö„Çä„Åì„Å°„Çâ„ÅØÂΩì„Çµ„Ç§„Éà„Åã„Çâ„ÅÆ„ÅîÈÄ£Áµ°„Åß„ÅØ„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„ÄÇÂÄã‰∫∫ÊÉÖÂ†±„ÇíÂèñÂæó„Åó„Çà„ÅÜ„Å®„Åô„ÇãË©êÊ¨∫„ÅåÁô∫Áîü„Åó„Å¶„ÅÑ„Çã„Çà„ÅÜ„Åß„Åô„ÅÆ„Åß„ÄÅ„ÅîÊ≥®ÊÑè„Åè„Å†„Åï„ÅÑ„Åæ„Åõ„ÄÇË®òËºâ„ÅÆÁï™Âè∑„Å´„ÅØÈÄ£Áµ°„Åó„Å™„ÅÑ„Çà„ÅÜ„ÅäÈ°ò„ÅÑ„ÅÑ„Åü„Åó„Åæ„Åô„ÄÇet                 1\n",
      "httpstcoplgarnzoq                                                                                                      1\n",
      "httpstcodspsg                                                                                                          1\n",
      "„Ç¢„Éû„Çæ„É≥„Åß„Åô„ÄÇÊ≥®ÊñáÂ±•Ê≠¥„Å´Ë®òËºâ„ÅÆ‰∫àÂÆöÊó•„ÇíÈÅé„Åé„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅØ„ÄÅÁô∫ÈÄÅÂÖÉ„Åå„Ç¢„Éû„Çæ„É≥„ÅÆÂ†¥Âêà‚Üíhttpstcontnaxsr„ÄÅÂá∫ÂìÅËÄÖ„ÅÆÂ†¥Âêà‚Üíhttpstcolwzsubyubc                                      1\n",
      "httpstcolghswactk                                                                                                      1\n",
      "slater                                                                                                                 1\n",
      "eripii                                                                                                                 1\n",
      "httpstcoqivzccvf                                                                                                       1\n",
      "‚Äòon‚Äô                                                                                                                   1\n",
      "danizinha                                                                                                              1\n",
      "httpstcoqxgvviak                                                                                                       1\n",
      "httpstcodjltufvux                                                                                                      1\n",
      "                                                                                                                      ..\n",
      "httpstcogfqenygaz                                                                                                      1\n",
      "httpstcozkqfqdpzi                                                                                                      1\n",
      "httpstcozeqlcdnr                                                                                                       1\n",
      "ethnik                                                                                                                 1\n",
      "chargerscowboy                                                                                                         1\n",
      "pregressively                                                                                                          1\n",
      "¬¥ÔΩ°ooÔºà„ÅäÂæÖ„Å°„Åó„Å¶„Åä„Çä„Åæ„ÅôÔΩû‚ô™                                                                                                       1\n",
      "¬¥ÔΩ°oo„Åü„Åè„Åï„Çì‰Ωø„Å£„Å¶„ÅäÊ•Ω„Åó„Åø„Åè„Å†„Åï„ÅÑ„Éª„Éª„Éª‚ú®‚ú®                                                                                               1\n",
      "lettera                                                                                                                1\n",
      "tomorrowcjay                                                                                                           1\n",
      "„Åì„Çì„Å´„Å°„ÅØ„ÄÅamazonÂÖ¨Âºè„Ç¢„Ç´„Ç¶„É≥„Éà„Åß„Åô„ÄÇÂïÜÂìÅËá™‰Ωì„ÅÆÂàùÊúü‰∏çËâØ„Åã„Å©„ÅÜ„Åã„ÅØ„ÄÅ‰∏ÄÂ∫¶„É°„Éº„Ç´„Éº„Å´„ÅäÂïèÂêà„ÅõÈ†Ç„Åç„ÄÅ„ÅîÁ¢∫Ë™ç„Åè„Å†„Åï„ÅÑ„ÄÇÂàùÊúü‰∏çËâØ„Å†„Å®Âà§Êñ≠„Åï„Çå„ÅüÂ†¥Âêà„Å´„ÅØ„ÄÅËøîÂìÅ„Åæ„Åü„ÅØ‰∫§Êèõ„ÇíÊâø„Çä„Åæ„Åô„ÅÆ„Åß„ÄÅamazon„Ç´„Çπ„Çø„Éû„Éº„Çµ„Éº„Éì„Çπ„Åæ„Åß„ÅäÂïèÂêà„Åõ‰∏ã„Åï„ÅÑ„ÄÇ    1\n",
      "httpstcobnjkhosxeo                                                                                                     1\n",
      "„Ç¶„Ç©„ÉÉ„ÉÅ„É™„Çπ„Éà„Åå„Éë„É≥„ÇØ„Åó„Å™„ÅÑ„ÅÜ„Å°„Å´„ÄÅ„Å°„Çá„Å£„Å®„Åö„Å§Ê∂àÂåñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„Åæ„Åõ„ÄÇ„Éó„É©„Ç§„É†„Éª„Éì„Éá„Ç™„ÄÅ„Å©„ÅÜ„Åû„ÅäÊ•Ω„Åó„Åø„Åè„Å†„Åï„ÅÑ‚ô™                                                               1\n",
      "weiterleitung                                                                                                          1\n",
      "arrays                                                                                                                 1\n",
      "gamma                                                                                                                  1\n",
      "infogtedit                                                                                                             1\n",
      "indah                                                                                                                  1\n",
      "httpstcokixidh                                                                                                         1\n",
      "√ºbersetzt                                                                                                              1\n",
      "httpstcojuggjyqzf                                                                                                      1\n",
      "daysthks                                                                                                               1\n",
      "httpstcobqmrxwlmr                                                                                                      1\n",
      "httpstcoitzbfymm                                                                                                       1\n",
      "httpstcoxllpugu                                                                                                        1\n",
      "httpstcocbdlrnoan                                                                                                      1\n",
      "synchroniser                                                                                                           1\n",
      "suss                                                                                                                   1\n",
      "msend                                                                                                                  1\n",
      "season‚Äîincluding                                                                                                       1\n",
      "Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "rareX = pd.Series(' '.join(inbOutb['text_x_clean']).split()).value_counts()[-100:]\n",
    "rareY = pd.Series(' '.join(inbOutb['text_y_clean']).split()).value_counts()[-100:]\n",
    "print('RARE X: \\n',rareX,'\\nRARE Y: \\n', rareY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing them\n",
    "rareX = list(rareX.index)\n",
    "rareY = list(rareY.index)\n",
    "inbOutb['text_x_clean'] = inbOutb['text_x_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in rareX))\n",
    "inbOutb['text_y_clean'] = inbOutb['text_y_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in rareY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing separates text into units such as sentences or words. It gives structure to previously unstructured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to Tokenize words\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text) #W+ means that either a word character (A-Za-z0-9_) or a dash (-) can go there.\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbOutb['text_x_tokenized'] = inbOutb['text_x_clean'].apply(lambda x: tokenize(x.lower())) \n",
    "inbOutb['text_y_tokenized'] = inbOutb['text_y_clean'].apply(lambda x: tokenize(x.lower()))\n",
    "#We convert to lower as Python is case-sensitive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_x_tokenized</th>\n",
       "      <th>text_y_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315288</th>\n",
       "      <td>390987</td>\n",
       "      <td>Sat Oct 14 23:33:37 +0000 2017</td>\n",
       "      <td>@115879 how many times should the system cance...</td>\n",
       "      <td>asklyft</td>\n",
       "      <td>Sun Oct 15 00:57:16 +0000 2017</td>\n",
       "      <td>@390987 Hello! We are sorry to hear this. Can ...</td>\n",
       "      <td>how many times should system cancel or change ...</td>\n",
       "      <td>hello are sorry hear dm phone number ached acc...</td>\n",
       "      <td>hello sorry hear dm us phone number ached acco...</td>\n",
       "      <td>[how, many, times, should, system, cancel, or,...</td>\n",
       "      <td>[hello, are, sorry, hear, dm, phone, number, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461149</th>\n",
       "      <td>507004</td>\n",
       "      <td>Sat Nov 04 20:52:57 +0000 2017</td>\n",
       "      <td>@ATVIAssist servers aren't working for me. Err...</td>\n",
       "      <td>atviassist</td>\n",
       "      <td>Mon Nov 06 09:34:53 +0000 2017</td>\n",
       "      <td>@507004 Apologies for the delay, things should...</td>\n",
       "      <td>servers arent working me error code but friend...</td>\n",
       "      <td>apologies delay things should be back now are ...</td>\n",
       "      <td>apologies delay things back still unable conne...</td>\n",
       "      <td>[servers, arent, working, me, error, code, but...</td>\n",
       "      <td>[apologies, delay, things, should, be, back, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510666</th>\n",
       "      <td>547353</td>\n",
       "      <td>Sun Oct 15 14:58:01 +0000 2017</td>\n",
       "      <td>@AskTarget FYI, App was updated on 10/13 and i...</td>\n",
       "      <td>asktarget</td>\n",
       "      <td>Sun Oct 15 20:11:54 +0000 2017</td>\n",
       "      <td>@547353 Thank you for letting us know. Can you...</td>\n",
       "      <td>fyi app was updated version</td>\n",
       "      <td>thank letting know dm date store location and ...</td>\n",
       "      <td>thank letting us know dm us date store locatio...</td>\n",
       "      <td>[fyi, app, was, updated, version]</td>\n",
       "      <td>[thank, letting, know, dm, date, store, locati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "315288      390987  Sat Oct 14 23:33:37 +0000 2017   \n",
       "461149      507004  Sat Nov 04 20:52:57 +0000 2017   \n",
       "510666      547353  Sun Oct 15 14:58:01 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "315288  @115879 how many times should the system cance...     asklyft   \n",
       "461149  @ATVIAssist servers aren't working for me. Err...  atviassist   \n",
       "510666  @AskTarget FYI, App was updated on 10/13 and i...   asktarget   \n",
       "\n",
       "                          created_at_y  \\\n",
       "315288  Sun Oct 15 00:57:16 +0000 2017   \n",
       "461149  Mon Nov 06 09:34:53 +0000 2017   \n",
       "510666  Sun Oct 15 20:11:54 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "315288  @390987 Hello! We are sorry to hear this. Can ...   \n",
       "461149  @507004 Apologies for the delay, things should...   \n",
       "510666  @547353 Thank you for letting us know. Can you...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "315288  how many times should system cancel or change ...   \n",
       "461149  servers arent working me error code but friend...   \n",
       "510666                        fyi app was updated version   \n",
       "\n",
       "                                             text_y_clean  \\\n",
       "315288  hello are sorry hear dm phone number ached acc...   \n",
       "461149  apologies delay things should be back now are ...   \n",
       "510666  thank letting know dm date store location and ...   \n",
       "\n",
       "                                             text_wo_stop  \\\n",
       "315288  hello sorry hear dm us phone number ached acco...   \n",
       "461149  apologies delay things back still unable conne...   \n",
       "510666  thank letting us know dm us date store locatio...   \n",
       "\n",
       "                                         text_x_tokenized  \\\n",
       "315288  [how, many, times, should, system, cancel, or,...   \n",
       "461149  [servers, arent, working, me, error, code, but...   \n",
       "510666                  [fyi, app, was, updated, version]   \n",
       "\n",
       "                                         text_y_tokenized  \n",
       "315288  [hello, are, sorry, hear, dm, phone, number, a...  \n",
       "461149  [apologies, delay, things, should, be, back, n...  \n",
       "510666  [thank, letting, know, dm, date, store, locati...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Remove StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords are common words that will likely appear in any text. They don‚Äôt tell us much about our data so we remove them. eg: silver or lead is fine for me-> silver, lead, fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english') # All English Stopwords\n",
    "\n",
    "# Function to remove Stopwords\n",
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]# To remove all stopwords\n",
    "    return text\n",
    "\n",
    "inbOutb['text_x_tokenized'] = inbOutb['text_x_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "inbOutb['text_y_tokenized'] = inbOutb['text_y_tokenized'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_x_tokenized</th>\n",
       "      <th>text_y_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315288</th>\n",
       "      <td>390987</td>\n",
       "      <td>Sat Oct 14 23:33:37 +0000 2017</td>\n",
       "      <td>@115879 how many times should the system cance...</td>\n",
       "      <td>asklyft</td>\n",
       "      <td>Sun Oct 15 00:57:16 +0000 2017</td>\n",
       "      <td>@390987 Hello! We are sorry to hear this. Can ...</td>\n",
       "      <td>how many times should system cancel or change ...</td>\n",
       "      <td>hello are sorry hear dm phone number ached acc...</td>\n",
       "      <td>hello sorry hear dm us phone number ached acco...</td>\n",
       "      <td>[many, times, system, cancel, change, drivers,...</td>\n",
       "      <td>[hello, sorry, hear, dm, phone, number, ached,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461149</th>\n",
       "      <td>507004</td>\n",
       "      <td>Sat Nov 04 20:52:57 +0000 2017</td>\n",
       "      <td>@ATVIAssist servers aren't working for me. Err...</td>\n",
       "      <td>atviassist</td>\n",
       "      <td>Mon Nov 06 09:34:53 +0000 2017</td>\n",
       "      <td>@507004 Apologies for the delay, things should...</td>\n",
       "      <td>servers arent working me error code but friend...</td>\n",
       "      <td>apologies delay things should be back now are ...</td>\n",
       "      <td>apologies delay things back still unable conne...</td>\n",
       "      <td>[servers, arent, working, error, code, friends...</td>\n",
       "      <td>[apologies, delay, things, back, still, unable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510666</th>\n",
       "      <td>547353</td>\n",
       "      <td>Sun Oct 15 14:58:01 +0000 2017</td>\n",
       "      <td>@AskTarget FYI, App was updated on 10/13 and i...</td>\n",
       "      <td>asktarget</td>\n",
       "      <td>Sun Oct 15 20:11:54 +0000 2017</td>\n",
       "      <td>@547353 Thank you for letting us know. Can you...</td>\n",
       "      <td>fyi app was updated version</td>\n",
       "      <td>thank letting know dm date store location and ...</td>\n",
       "      <td>thank letting us know dm us date store locatio...</td>\n",
       "      <td>[fyi, app, updated, version]</td>\n",
       "      <td>[thank, letting, know, dm, date, store, locati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "315288      390987  Sat Oct 14 23:33:37 +0000 2017   \n",
       "461149      507004  Sat Nov 04 20:52:57 +0000 2017   \n",
       "510666      547353  Sun Oct 15 14:58:01 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "315288  @115879 how many times should the system cance...     asklyft   \n",
       "461149  @ATVIAssist servers aren't working for me. Err...  atviassist   \n",
       "510666  @AskTarget FYI, App was updated on 10/13 and i...   asktarget   \n",
       "\n",
       "                          created_at_y  \\\n",
       "315288  Sun Oct 15 00:57:16 +0000 2017   \n",
       "461149  Mon Nov 06 09:34:53 +0000 2017   \n",
       "510666  Sun Oct 15 20:11:54 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "315288  @390987 Hello! We are sorry to hear this. Can ...   \n",
       "461149  @507004 Apologies for the delay, things should...   \n",
       "510666  @547353 Thank you for letting us know. Can you...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "315288  how many times should system cancel or change ...   \n",
       "461149  servers arent working me error code but friend...   \n",
       "510666                        fyi app was updated version   \n",
       "\n",
       "                                             text_y_clean  \\\n",
       "315288  hello are sorry hear dm phone number ached acc...   \n",
       "461149  apologies delay things should be back now are ...   \n",
       "510666  thank letting know dm date store location and ...   \n",
       "\n",
       "                                             text_wo_stop  \\\n",
       "315288  hello sorry hear dm us phone number ached acco...   \n",
       "461149  apologies delay things back still unable conne...   \n",
       "510666  thank letting us know dm us date store locatio...   \n",
       "\n",
       "                                         text_x_tokenized  \\\n",
       "315288  [many, times, system, cancel, change, drivers,...   \n",
       "461149  [servers, arent, working, error, code, friends...   \n",
       "510666                       [fyi, app, updated, version]   \n",
       "\n",
       "                                         text_y_tokenized  \n",
       "315288  [hello, sorry, hear, dm, phone, number, ached,...  \n",
       "461149  [apologies, delay, things, back, still, unable...  \n",
       "510666  [thank, letting, know, dm, date, store, locati...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tokenizing separates text into units such as sentences or words. It gives structure to previously unstructured text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming helps reduce a word to its stem form. It often makes sense to treat related words in the same way. It removes suffices, like ‚Äúing‚Äù, ‚Äúly‚Äù, ‚Äús‚Äù, etc. by a simple rule-based approach.\n",
    "It reduces the corpus of words but often the actual words get neglected. eg: Entitling,Entitled->Entitl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inbOutb['text_x_stemmed'] = inbOutb['text_x_nostop'].apply(lambda x: stemming(x))\n",
    "# inbOutb['text_y_stemmed'] = inbOutb['text_y_nostop'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing derives the canonical form (‚Äòlemma‚Äô) of a word. i.e the root form. It is better than stemming as it uses a dictionary-based approach i.e a morphological analysis to the root word.eg: Entitling, Entitled->Entitle <br>\n",
    "In Short, Stemming is typically faster as it simply chops off the end of the word, without understanding the context of the word. Lemmatizing is slower and more accurate as it takes an informed analysis with the context of the word in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbOutb['text_x_lemmatized'] = inbOutb['text_x_tokenized'].apply(lambda x: lemmatizing(x))\n",
    "inbOutb['text_y_lemmatized'] = inbOutb['text_y_tokenized'].apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_x_clean</th>\n",
       "      <th>text_y_clean</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_x_tokenized</th>\n",
       "      <th>text_y_tokenized</th>\n",
       "      <th>text_x_lemmatized</th>\n",
       "      <th>text_y_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315288</th>\n",
       "      <td>390987</td>\n",
       "      <td>Sat Oct 14 23:33:37 +0000 2017</td>\n",
       "      <td>@115879 how many times should the system cance...</td>\n",
       "      <td>asklyft</td>\n",
       "      <td>Sun Oct 15 00:57:16 +0000 2017</td>\n",
       "      <td>@390987 Hello! We are sorry to hear this. Can ...</td>\n",
       "      <td>how many times should system cancel or change ...</td>\n",
       "      <td>hello are sorry hear dm phone number ached acc...</td>\n",
       "      <td>hello sorry hear dm us phone number ached acco...</td>\n",
       "      <td>[many, times, system, cancel, change, drivers,...</td>\n",
       "      <td>[hello, sorry, hear, dm, phone, number, ached,...</td>\n",
       "      <td>[many, time, system, cancel, change, driver, r...</td>\n",
       "      <td>[hello, sorry, hear, dm, phone, number, ached,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461149</th>\n",
       "      <td>507004</td>\n",
       "      <td>Sat Nov 04 20:52:57 +0000 2017</td>\n",
       "      <td>@ATVIAssist servers aren't working for me. Err...</td>\n",
       "      <td>atviassist</td>\n",
       "      <td>Mon Nov 06 09:34:53 +0000 2017</td>\n",
       "      <td>@507004 Apologies for the delay, things should...</td>\n",
       "      <td>servers arent working me error code but friend...</td>\n",
       "      <td>apologies delay things should be back now are ...</td>\n",
       "      <td>apologies delay things back still unable conne...</td>\n",
       "      <td>[servers, arent, working, error, code, friends...</td>\n",
       "      <td>[apologies, delay, things, back, still, unable...</td>\n",
       "      <td>[server, arent, working, error, code, friend, ...</td>\n",
       "      <td>[apology, delay, thing, back, still, unable, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510666</th>\n",
       "      <td>547353</td>\n",
       "      <td>Sun Oct 15 14:58:01 +0000 2017</td>\n",
       "      <td>@AskTarget FYI, App was updated on 10/13 and i...</td>\n",
       "      <td>asktarget</td>\n",
       "      <td>Sun Oct 15 20:11:54 +0000 2017</td>\n",
       "      <td>@547353 Thank you for letting us know. Can you...</td>\n",
       "      <td>fyi app was updated version</td>\n",
       "      <td>thank letting know dm date store location and ...</td>\n",
       "      <td>thank letting us know dm us date store locatio...</td>\n",
       "      <td>[fyi, app, updated, version]</td>\n",
       "      <td>[thank, letting, know, dm, date, store, locati...</td>\n",
       "      <td>[fyi, app, updated, version]</td>\n",
       "      <td>[thank, letting, know, dm, date, store, locati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id_x                    created_at_x  \\\n",
       "315288      390987  Sat Oct 14 23:33:37 +0000 2017   \n",
       "461149      507004  Sat Nov 04 20:52:57 +0000 2017   \n",
       "510666      547353  Sun Oct 15 14:58:01 +0000 2017   \n",
       "\n",
       "                                                   text_x author_id_y  \\\n",
       "315288  @115879 how many times should the system cance...     asklyft   \n",
       "461149  @ATVIAssist servers aren't working for me. Err...  atviassist   \n",
       "510666  @AskTarget FYI, App was updated on 10/13 and i...   asktarget   \n",
       "\n",
       "                          created_at_y  \\\n",
       "315288  Sun Oct 15 00:57:16 +0000 2017   \n",
       "461149  Mon Nov 06 09:34:53 +0000 2017   \n",
       "510666  Sun Oct 15 20:11:54 +0000 2017   \n",
       "\n",
       "                                                   text_y  \\\n",
       "315288  @390987 Hello! We are sorry to hear this. Can ...   \n",
       "461149  @507004 Apologies for the delay, things should...   \n",
       "510666  @547353 Thank you for letting us know. Can you...   \n",
       "\n",
       "                                             text_x_clean  \\\n",
       "315288  how many times should system cancel or change ...   \n",
       "461149  servers arent working me error code but friend...   \n",
       "510666                        fyi app was updated version   \n",
       "\n",
       "                                             text_y_clean  \\\n",
       "315288  hello are sorry hear dm phone number ached acc...   \n",
       "461149  apologies delay things should be back now are ...   \n",
       "510666  thank letting know dm date store location and ...   \n",
       "\n",
       "                                             text_wo_stop  \\\n",
       "315288  hello sorry hear dm us phone number ached acco...   \n",
       "461149  apologies delay things back still unable conne...   \n",
       "510666  thank letting us know dm us date store locatio...   \n",
       "\n",
       "                                         text_x_tokenized  \\\n",
       "315288  [many, times, system, cancel, change, drivers,...   \n",
       "461149  [servers, arent, working, error, code, friends...   \n",
       "510666                       [fyi, app, updated, version]   \n",
       "\n",
       "                                         text_y_tokenized  \\\n",
       "315288  [hello, sorry, hear, dm, phone, number, ached,...   \n",
       "461149  [apologies, delay, things, back, still, unable...   \n",
       "510666  [thank, letting, know, dm, date, store, locati...   \n",
       "\n",
       "                                        text_x_lemmatized  \\\n",
       "315288  [many, time, system, cancel, change, driver, r...   \n",
       "461149  [server, arent, working, error, code, friend, ...   \n",
       "510666                       [fyi, app, updated, version]   \n",
       "\n",
       "                                        text_y_lemmatized  \n",
       "315288  [hello, sorry, hear, dm, phone, number, ached,...  \n",
       "461149  [apology, delay, thing, back, still, unable, c...  \n",
       "510666  [thank, letting, know, dm, date, store, locati...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbOutb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inbOutb.to_csv('inbOutb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the library with the CountVectorizer method\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "questions = inbOutb['text_x_clean'].dropna()\n",
    "q = np.array(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the count vectorizer with the English stop words\n",
    "countV = CountVectorizer(stop_words='english',\n",
    "                         max_features=10000)\n",
    "\n",
    "# Fit and transform the processed titles\n",
    "bagQuestions = countV.fit_transform(q)\n",
    "\n",
    "print('BOW Questions: ',bagQuestions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordcloud with the most common words in customer requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Positive Vs Negative Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tweets = pd.read_csv('twcs.csv')\n",
    "inbound_tweets = tweets[tweets.inbound == True]\n",
    "inbound_tweets['timestamp'] = pd.to_datetime(inbound_tweets['created_at']).dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Explore the dataset for inbound tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(inbound_tweets.head())\n",
    "display(inbound_tweets.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Collect quantities by author:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_author_id = inbound_tweets.groupby(['author_id']) \\\n",
    "    .count()[['tweet_id']] \\\n",
    "    .sort_values(['tweet_id'], ascending = False) \\\n",
    "    .rename({'tweet_id': 'qty'}, axis='columns')\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(count_by_author_id.index.values)), count_by_author_id.qty )\n",
    "plt.xlabel('Author #')\n",
    "plt.ylabel('Tweets Qty.')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Quantities by Date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_date = inbound_tweets.groupby(['timestamp']) \\\n",
    "    .count()[['tweet_id']] \\\n",
    "    .sort_values(['timestamp'], ascending = True) \\\n",
    "    .rename({'tweet_id': 'qty'}, axis='columns')\n",
    "\n",
    "display(count_by_date.head())\n",
    "plt.figure()\n",
    "plt.plot(count_by_date.index.values, count_by_date.qty )\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Tweets Qty.')\n",
    "plt.grid(True)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Process the sentiment analysis using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "inbound_tweets['score'] = inbound_tweets.text.apply(lambda x: sentiment_analyzer.polarity_scores(x)['compound'])\n",
    "display(inbound_tweets.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Check the Sentiment Analysis with an histogram of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_bins = 30\n",
    "plt.figure(figsize=[10,5])\n",
    "x = inbound_tweets[['score']]\n",
    "scores_hist,edges = np.histogram(x, bins=hist_bins)\n",
    "plt.bar(edges[:-1], scores_hist)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Tweets Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.6 Define limit for Pos. vs Neg. comment and compute results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_pos = 0.5\n",
    "limit_neg = -0.5\n",
    "limit_neg_per_author = 3\n",
    "#plt.plot(inbound_tweets.index.values, inbound_tweets['score'], 'r')\n",
    "#plt.axhline(0.5, 'g.')\n",
    "inbound_tweets['is_pos'] = (inbound_tweets[['score']] > limit_pos)\n",
    "inbound_tweets['is_neg'] = (inbound_tweets[['score']] < limit_neg)\n",
    "inbound_tweets['is_other'] = ~inbound_tweets.is_pos & ~inbound_tweets.is_neg\n",
    "\n",
    "def count_true(x):\n",
    "    return np.sum(x == True)\n",
    "\n",
    "scores_by_date = inbound_tweets.groupby(['timestamp']) \\\n",
    "    .agg({'tweet_id':'count', 'is_pos': count_true, 'is_neg': count_true, 'is_other': count_true}) \\\n",
    "    .rename({'tweet_id':'total'}, axis='columns')\n",
    "display(scores_by_date.head())\n",
    "x = scores_by_date.index.values\n",
    "y1 = scores_by_date['is_pos']\n",
    "y2 = scores_by_date['is_neg']\n",
    "\n",
    "scores_by_author = inbound_tweets.groupby(['author_id']) \\\n",
    "    .agg({'tweet_id':'count','is_neg': count_true}) \\\n",
    "    .rename({'tweet_id':'total'}, axis='columns')\n",
    "scores_by_author = scores_by_author.loc[scores_by_author['is_neg'] >= limit_neg_per_author]\n",
    "display(scores_by_author.head())\n",
    "\n",
    "#plt.scatter(x, y, alpha=0.5)\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.plot(x, y1,'g-', x, y2, 'r--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Qty.')\n",
    "plt.legend(['Pos.Tweet', 'Neg.Tweet'])\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
